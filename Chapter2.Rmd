# Literature Review

In this section, the research question is decomposed into its component topics and each is reviewed systematically and in detail. The topics are covered in a logical order that reflect the motivation for this research: The breadth of use of surveys and questionnaires and the problem of missing data, the well-understood underlying models and current popular solutions. The potential suitability of association rules as a basis for a new imputation method is explored in the later subsections.

## The Importance of Surveys and Questionnaires

@groves2011three [p. 861] states that "the systematic observation of social and economic phenomena has roots deep in history" but describes the 1930's-1960's period as foundational for the development and popularization of the survey method involving structured questions, random sampling and statistical inference. It was also a golden age with respect to response rates, perhaps due to the novelty and the small numbers of surveys carried out, relative to today. Understandably, the earlier historical discussions in this article are backed up by fewer references than paragraphs covering more recent decades. Nevertheless, the author is well regarded and prolific on this subject matter. As a potted history of surveys and questionnaires, the article provides a very plausible interpretation of the influence of sociological and technological factors which explain why the survey method became so ubiquitous up to and during the 1990's but began to see a decline in usage thereafter. For example, one suggestion is that the popularity of the method was driven in part by usage in the consumer and service sectors as a means to gain customer feedback and thereby maximize profits. This speaks to economic common sense. The aid of computers in the 1960's reducing processing costs and allowing greater numbers of participants e.g. hundreds of thousands [@schultz2015psychology p.32] and more sophisticated computational analysis would have been another driver both in commerce and government research. In academia, the publication of archived data "permitted the rise of quantitative methods in many social science disciplines," @groves2011three [p. 865]. 

Consistent with the description of a decline in popularity, @sheehan2001mail posits that even the change from face-to-face and postal to email-based surveys provided only a temporary stay in the overall decline in usage in more recent times. However, there is no shortage of examples to suggest that the method is still incredibly important today, [@shrive2006dealing; @schultz2015psychology] *more citations*. In fact @schultz2015psychology suggests that merely carrying out a survey in an industrial/organisational setting can raise staff morale and reduce conflict between management and unions. 

@groves2011three goes on to make a number of reasoned predictions about future adaptations of the survey method in light of the emergence of a multitude of new data sources (of which the author's description matches what is now commonly coined as "Big Data") and continues to suggest that these new sources of data are collected organically, i.e. they are "unstructured", so there's an ongoing requirement for the designed data of surveys. One technological development is not discussed in detail in the article, namely the emerging popularity of online surveys construction software (SurveyMonkey, Qualtrix, www.onlinesurveys.ac.uk, SmartSurvey, SogoSurvey to name but a few). This could be because the article is not recent enough or perhaps as @solomon2001conducting describes, because of the caution with which this new technology was viewed by the academic community. Such caution may relate to statistical issues such as coverage bias resulting from "the skew in demographics of the internet population versus the general public" [@hayslett2005pixels p. 78] combined with the practical need for researchers to become more familiar with the technology before being able to construct surveys with sufficiant statistical rigour. Nevertheless, @schultz2015psychology states that most companies now use web-based surveys and @evans2005value shows that online surveys were already a rapidly growing, multi-million dollar industry by the early 2000's. The article describes many weaknesses as well as strengths in the sector. Indeed, it was very much a clarion call for addressing the weaknesses to consolidate the value of online surveys for the modern day. It would be safe to assume that these have been addressed for there has been a rise and rise of services for the creation of casual surveys and polls by the "citizen analyst" as well as seasoned pollsters which are distributed through social media and quick customer ratings devices. These technological innovations may introduce the need for development of new methods that stand up to analytical scrutiny but they do offer new opportunities given their widespread dissemination.

## Characteristics of Survey Data and Prevalent Data Types

Researchers in the social sciences and other disciplines often use surveys to collect data on subjective attitudes, perceptions and psychological traits. @johnson2009working states that nominal and ordinal variables are predominant and this makes sense when survey design considerations are taken into account. In this respect @schultz2015psychology [p.37] explains that "fixed-alternative questions simplify the survey and allow more questions to be asked," and also "answers to fixed-alternative questions can be recorded more easily and accurately than can answers to open ended questions." Furthermore, when collecting demographic information, apart from height and weight, most routine information will be categorical in nature, e.g. eye colour, hair colour, ethnic origin.

Surveys frequently use Ordinal (ranking) responses, sometimes individually but often combining multiple related items. @johnson2009working also gives detailed examples of why ordinal variables cannot be treated the same as numerical scales and @gertheiss2009penalized explains how this assertion holds even when the ordinal variable is a discretised version of an underlying continuous scale. Essentially, this is because the interpretation depends on arbitrarily assigned categories and mid-point estimates. Upper and lower unbound categories may hide any number of extreme values.

Likert scales are a special case of multiple-item response whereby a collection of statements are scored by the respondent using an integer series which is anchored to phrases of sentiment or attitude (e.g. 1 = strongly disagree, 5 = strongly agree). Likert scales are ubiquitous in behavioural science, marketing, customer feedback and usubility research. They are intended to measure the outwardly manifested facets of some latent concept or factor. As such, the individuals' positions on the latent concept can be obtained through appropriately aggregating, summing or transforming the multiple responses of the Likert scale items [@carpita2011imputation]. 

When analyzing Likert and similar scales, @jamieson2004likert posits that it is inappropriate even to use mean and standard deviations because it is wrong to presume that intervals between categories are equal. That is to say, the barrier to reach the highly polarised strongly disagree or strongly agree may be inconsistent with a move from neutral to either agree or disagree. Also, these types of scales are often skewed or multimodal and require non-parametric tests such as Mann-Whitney-Wilcoxon (MWW) for analysis. @gliem2003calculating states that these data types are often intended to be used as a combined scale, measuring a latent concept, and asserts that their individual analysis leads to erroneous conclusions. Other authors [@norman2010likert; @carifio2008resolving] strongly rebut these arguments, citing various sources of empirical evidence of the robustness of parametric tests. This is one of the great debates of statistics in the last few decades but there is agreement that combining individual responses into their intended scale leads to the least controversial usage and analytical or probabilistic techniques over single items in a Likert scale should be avoided where possible. @de2010five compares the type I and type II error rates of the t-test MWW test using synthetic data which finds that there is no benefit to either test with respect to type I errors and slight differences in performance with type II error rates, and consequently the power of the test. The direction of these differences depends on the underlying populations and may favour t-tests in some cases and MWW in others. Crucially, this article only tests a single variable, and so does little to settle the debate.

## Non-Response and Missingness

The practicalities of running surveys means that they regularly suffer the problem of non-response and missing data [@bono2007missing; @kamakura2000factor; @plumpton2016multiple]. In the broadest terms, non-response can occur at two levels: Unit and Item. Unit non-response occurs when one or more respondents fail to return anything to the survey organisers. This may be a one-off survey, or may be one in a series of surveys in a longitudinal study. If the non-response rate is high, this can impact the overall sampling frame. Item non-response occurs when individual items (questions) in a survey are skipped, but the whole survey is returned to the organisers. Both types of non-response have serious consequences. However, this work is concerned only with item non-response which will be the focus for the remainder of the review, unless otherwise stated. Understanding the model (patterns, mechanism and magnitude) of missingness in data is critical when selecting or designing techniques to recover from the resulting issues. Fortunately, there has been an enormous amount of research in this area over recent decades.

As always, routine exploratory analysis is the best starting point. For example, when examining the effect of survey length on response rates, @sheehan2001mail reports numerous prior studies that illustrate how longer surveys tend to reduce overall (unit) response rates, particularly for business-oriented surveys. Only one example is given of a study that found the opposite pattern but it is unclear if this is enough to call the overall trend into question. Crucially, there is no discussion of the implication of survey length on any pattern of item non-response and specifically whether longer surveys suffer more incomplete items towards the end than near the beginning. From the historical outline given in @groves2011three, this must be assumed to be the case, given that the focus shifted to shorter questionnaires to reduce hang-up rates at the same time as an increase in popularity of surveys by telephone. A ragged tail pattern of non-response would be a clear indicator of a survey that respondents found overly long.


```{r nonresp-reasons}
reason <- c("Failure to complete the whole questionnaire"
          , "Failure to complete the whole questionnaire"
          , "Unwillingness to answer"
          , "Unwillingness to answer"
          , "Data entry errors"
          , "Data entry errors"
          , "Structural design of questionnaire"
          , "Structural design of questionnaire")
cause <- c("Absent-mindedness"
          , "Skipping a page in error"
          , "Personal issues: income, status, health"
          , "Perceived not relevant to study: drug use, sexual orientation"
          , "Manual conversion of paper forms"
          , "Using incorrect marking of papers e.g. check instead of filled box"
          , "Some questions only apply depending on previous answers"
          , "Poorly designed e.g. too long"
           )
reasonstable <- data.frame(Reason = reason
                  , "Examples" = cause)
knitr::kable(reasonstable
             , caption = "Reasons for item non-response")
```

Table \@ref(tab:nonresp-reasons) is shows a non-exhaustive list of examples of reasons for item non-response. In a single survey instance, more than one such reason could be at play for different items. These different underlying models have various consequences and researchers may have no way of knowing for sure what are the mechanisms behind missingness in the data.

```{r nonresp-patterns}
pattern <- c("Univariate"
             , "Multivarate"
             , "Ragged tail"
             , "Missing blocks"
             , "Missing blocks"
             , "Missing regular")
explanation <- c("Only one item has missing responses"
                 , "Missing responses throughout, seemingly at random"
                 , "Missing all after a certain question"
                 , "Groups of respondents reply to different questions"
                 , "Groups of respondents reply to different questions"
                 , "Questions skipped depending on prior responses")
posscause <- c("Badly worded or irrelevant question"
               , "Any"
               , "Survey is too long"
               , "Data fusion: different surveys combined"
               , "A subsample participate in follow ups"
               , "Structural constraints")
patternstable <- data.frame(Pattern = pattern
                            , Explanation = explanation
                            , Possible_Cause = posscause)

knitr::kable(patternstable
             , caption = "Patterns of non-response"
             , booktabs = TRUE)
```

Table \@ref(tab:nonresp-patterns) and figures \@ref(fig:univmissingness), \@ref(fig:multmissingness), \@ref(fig:mtailmissingness), \@ref(fig:dfusmissingness), \@ref(fig:sbsmmissingness) and \@ref(fig:stdgmissingness) are adapted from @kamakura2000factor to illustrate patterns of both unintentional (1-3) and intentional (4-6) non-response in surveys. These also demonstrate the usefulness of the missing values map, @unwin1996interactive. This is a simple, exploratory plot of a missing indicator matrix. This is a binary matrix representing presence or absence of a value for each respondent and item. Some articles [@he2010missing] recommend using a one to represent a missing value and a zero for present values as this reflects binomial success of the non-response process. However, other authors [@gelman2006data] put forward cases where the reverse makes sense. Clearly, it can be argued that this choice does not matter, so long as the research method is implemented with clarity.

```{r univmissingness, fig.height=2, fig.width=2, fig.cap="Missing Values Map showing univariate missingness"}
set.seed(101)
qnnaire <- matrix(rep(1, 2000), nrow = 100, ncol = 20)

umsng <- rbinom(100, 1, 1 - 0.2)
univ <- qnnaire
univ[, 13] <- umsng

par(mar = c(1, 1, 1, 1)
    , mgp = c(0, 0, 0)
    , cex.main = 0.8)

image(t(univ)
      , main = "Univariate Pattern"
      , xlab = "Item"
      , ylab = "Respondent"
      , xaxt = "n"
      , yaxt = "n"
      , col = c("ivory", "darkslateblue"))
```

```{r multmissingness, fig.height=2, fig.width=2, fig.cap="Missing Values Map showing multivariate missingness"}
mult <- matrix(rbinom(2000, 1, 1 - 0.05), nrow = 100, ncol = 20)

par(mar = c(1, 1, 1, 1)
    , mgp = c(0, 0, 0)
    , cex.main = 0.8)
  
image(t(mult)
      , main = "Multivariate Pattern"
      , xlab = "Item"
      , ylab = "Respondent"
      , xaxt = "n"
      , yaxt = "n"
      , col = c("ivory", "darkslateblue"))
```

```{r mtailmissingness, fig.height=2, fig.width=2, fig.cap="Missing Values Map showing ragged tail missingness"}
mult <- matrix(rbinom(2000, 1, 1 - 0.05), nrow = 100, ncol = 20)

mtail <- qnnaire
mtmsng <- rbinom(100, 1, 1 - 0.1)
mtrow <- which(mtmsng == 0)
mtcount <- 100 - sum(mtmsng)
mtcol <- round(runif(mtcount, 15, 20))

for (i in seq_along(mtrow)) {
  mtail[mtrow[i], mtcol[i]:20] <- 0  
}

par(mar = c(1, 1, 1, 1)
    , mgp = c(0, 0, 0)
    , cex.main = 0.8)
  
image(t(mtail)
      , main = "Ragged Tail Pattern"
      , xlab = "Item"
      , ylab = "Respondent"
      , xaxt = "n"
      , yaxt = "n"
      , col = c("ivory", "darkslateblue"))
```

```{r dfusmissingness, fig.height=2, fig.width=2, fig.cap="Missing Values Map showing data fusion missingness"}
dfus <- qnnaire
dfus[1:50, 11:15] <- 0
dfus[51:100, 6:10] <- 0

par(mar = c(1, 1, 1, 1)
    , mgp = c(0, 0, 0)
    , cex.main = 0.8)

image(t(dfus)
      , main = "Data Fusion Pattern"
      , xlab = "Item"
      , ylab = "Respondent"
      , xaxt = "n"
      , yaxt = "n"
      , col = c("ivory", "darkslateblue"))
```

```{r sbsmmissingness, fig.height=2, fig.width=2, fig.cap="Missing Values Map showing subsample missingness"}
sbsm <- qnnaire
sbsm[26:100, 15:20] <- 0

par(mar = c(1, 1, 1, 1)
    , mgp = c(0, 0, 0)
    , cex.main = 0.8)

image(t(sbsm)
      , main = "Subsample Pattern"
      , xlab = "Item"
      , ylab = "Respondent"
      , xaxt = "n"
      , yaxt = "n"
      , col = c("ivory", "darkslateblue"))
```

```{r stdgmissingness, fig.height=2, fig.width=2, fig.cap="Missing Values Map showing structural design missingness"}
stdg <- qnnaire
stdg_skip1 <- which(rbinom(100, 1, 1 - 0.1) == 0)
stdg_skip2 <- which(rbinom(100, 1, 1 - 0.2) == 0)
stdg[stdg_skip1, 5:6] <- 0
stdg[stdg_skip2, 10:13] <- 0

par(mar = c(1, 1, 1, 1)
    , mgp = c(0, 0, 0)
    , cex.main = 0.8)

image(t(stdg)
      , main = "Structural Pattern"
      , xlab = "Item"
      , ylab = "Respondent"
      , xaxt = "n"
      , yaxt = "n"
      , col = c("ivory", "darkslateblue"))
```

Secondary citation of Roth 1994 in @plumpton2016multiple that conspicuously little research done on missing data analysis, despite importance in the social sciences, and there is still a gap in practice with what is recommended in the literature with 45% of papers surveyd using complete case analysis and only 8% using MI @plumpton2016multiple secondary citation of Bell ML, Fiero M, Horton NJ, et al. Donald B. Rubin is widely cited for seminal works on modeling, recovering (imputing) and inference using missing data e.g. @rubin2004multiple. Of particular importance in this body of work is formalization of the relationship between the missing values, the incomplete variable and the other variables. The patterns arising from these relationships are categorized as:

* Missing completely at random (MCAR) if process that causes the missing data is distinct from any parameter $\theta$ of the data. In other words the distribution of missing data is unrelated to the value of any variable in the dataset. It is also suggested in @gelman2006data that the probability of non-response is the same for all points of the missing indicator matrix. The missing/non-missing state of individual data points cannot be predicted from any information whatever, whether observed or unobserved other than the overall missingness rate.

* Missing at random (MAR) is the most common scenario according to @schafer1997analysis and applies if the distribution of missing data may be related to available information. That is, other variables in the dataset but not the variable itself. The mechanism is correlated with the observed data according to @gelman2006data, it is often reasonable to model this as a logistic regression. The article continues to assert that it is generally not possible to be certain even of an MAR assumption because a correlation with unobserved data or a latent variable can never be ruled out altogether.

* Missing not at random (MNAR) if the distribution of missing data is related to data that is unobserved. @gelman2006data further sub-divides this category in two. Firstly, when missingness depends on unobserved predictors, for example, dissatisfied customers being less likely to respond than satisfied customers would generate a MNAR unit non-response. An example of an MNAR unit non-response might be a survey where people in a particular education bracket responded less frequently to questions about income where there were no questions identifying the level of educational attainment. The second sub-division is where the distribution of missing data is related to the value of the partially missing variable itself, such that answers given by complete respondents differ substantially from answers that would have been given by non-respondents. For example, if respondents from a lower income bracket are reluctant to respond to questions about earnings. This is the most challenging situation to recover and of most concern to researchers. In fact, @tsikriktsis2005review states that there are no statistical means to recover when missing data is MNAR and no way to ameliorate the potential bias in results based on analysis of such data. While it is not explicit in the article, @tsikriktsis2005review must be referring to this second sub-division of the category. @gelman2006data contradicts this assertion by suggesting that the problem can be mitigated by adding more predictors. However, this assumes that more data is available when it would be expected that most researchers would provide all the data they have. 

In a historic article, @rubin1976inference lays the foundation for these definitions, which are now used throughout the literature, and deteremines that ignoring the mechanism of non-response is the proper procedure when, and only when, the data is MCAR. Missingness in MAR cases is "ignorable" in regression models only when controlling for all the variables that correlate with non-response. This is an important milestone in statistics discourse and after this time, references to these assumptions and the terms "ignorable" and "not ignorable" (with respect to non-response) are seen in results analysis generally. Furthermore, @gelman2006data also suggests that most missingness is not MCAR. This means that most missingness is not ignorable, which is a crucially important point for any statistical analysis. It is vital to make clear statements of assumptions made about missingness in data and its treatment prior to releasing results. @white2011multiple secondary citation of Sterne et al. suggest reporting guidelines that include careful comparison of MI results with the results of complete-case analysis [46].  @plumpton2016multiple secondary citation of Bell ML, Fiero M, Horton NJ, et al. says this doesn't happen as much as it should. Up to 66% of papers surveyed in psychology there was an implication that missing data was present but no mention how it was handled.

There is an abundance of examples in the literature of the adverse effects of missingness in survey data. These include biased parameter estimates (central tendency, dispersion and correlation coefficients) and loss of statistical power [@madow1983incomplete; @bean1995long; @roth1999missing; @raaijmakers1999effectiveness]. **Check if these discuss the recovery method used**

Carpita has some useful stuff on models of missing data

@white2011multiple quoted  Inadequate handling of the missing data in a statistical analysis can lead to biased and/or inefficient estimates of parameters such as means or regression coefficients, and biased standard errors resulting in incorrect confidence intervals and significance tests. In all statistical analyses, some assumptions are made about the missing data. Little and Rubin’s framework [1] is often used to classify the missing data as being (i) missing completely at random (MCAR—the probability of data being missing does not depend on the observed or unobserved data), (ii) missing at random (MAR—the probability of data being missing does not depend on the unobserved data, conditional on the observed data) or (iii) missing not at random (MNAR—the probability of data being missing does depend on the unobserved data, conditional on the observed data). For example, blood pressure data are MAR if older individuals are more likely to have their blood pressure recorded (and age is included in the analysis), but they are MNAR if individuals with high blood pressures are more likely to have their blood pressure recorded than other individuals of the same age. It is not possible to distinguish between MAR and MNAR from the observed data alone, although the MAR assumption can be made more plausible by collecting more explanatory variables and including them in the analysis.

10. facotr analysis method
500. plausible values
has some stuff on missing data simul.

## Techniques for Recovering from Missingness

It may be a case of stating the obvious, but bears repeating that prevention is always better than cure. @plumpton2016multiple [p.13] is unequivocal, stating that "it is the duty of researchers and analysts to firstly minimise the extent of missing data by ensuring appropriate methods for enhancing data capture are implemented, but also to handle missingness in a way best suited to the data and research question." The latter sentiment provides support for the motivation behind this research. Analytical and processing techniques should be carefully chosen to match data with different characteristics.

To give some idea of the motivation for missing data analysis and recovery per se,  @gelman2006data [p.529] describes non-response in a social indicators survey as "a distraction to our main goal of studying trends in attitudes and economic conditions, and we would like to simply clean the dataset so it could be analyzed as if there were no missingness." This  statement perfectly sums up the reason why so many techniques have been developed to make it possible to analyze a dataset with confidence and statistical rigour, despite the prevalence of non-response. Many statistical functions and operations simply do not work with missing data, whether calculated manually or by software. Many software systems (e.g. R, SAS, SPSS), whether silently or with a warning will automatically exclude cases with any missing values in the variables under analysis. This default list-wise deletion is only appropriate for data which is MCAR. **cite** It is therefore necessary to implement some form of pre-processing to recover a dataset for appropriate analysis and it can be argued that the method chosen will have a significant impact on the reliability of any subsequent analysis.

@gelman2006data complete case analyis is equivalent to listwise deletion. Data are thrown away as whole cases. Problems if missing data differe systematically from non-missing MNAR, this leads to biased estimates of population parameters. If there are many variables (wide dataset), then even a low proportion of missing could lead to most data being discarded. Available case analysis is using portions of the dataset with complete cases to answer different research questions. Problem is that analysis are based on inconsistent subsamples, representing potentially different populations. 70% of men answer one thing but only 60% of women answer it. Weighting methods add a weight to make complete cases more representative but this is very complicated in anything other than the univariate missingness. Single imputation strategies lead to variance estimates that are too low - because these "simulate knowing the true value with certainty." Mean imputation biases standard deviations and correlations downwards. Last value carried forward is only applicable in longitudinal, or time-based surveys. Create erratic results for trends analysis. Unordered categories, just add a missing category. Logical rules, using domain knowledge and structure in the survey - worked no hours, income = 0. Simple (naive) random imputation in the univariate case will substitute missing values with values that are sampled with replacement from the complete values. This ignores any useful information from the other variables. Can use zero coding, top/bottom coding to reduce sensitivity to extreme values and improve the predictive power of the model. A simple cutoff or a transform above a cutoff. Linear model prediction increases central tendency - see @gelman2006data for equations why based on R squared page 536. Random prediction imputation, for univariate normal data, or data which has been transformed to be so, can create a random normal vector from the vector of pred values (means) and resid st.devs as the st.dev so the scatter is defived from the unexplained variance in the model. Transforms and multi-stage imputations required for non-normal data (counts, zero-inflated modes and so on.)

Cold-deck imputation is where substitute values are found in prior studies. This is not generally talked about in the statistical literature, which focuses on statistical and computational techniques.

also quoted @plumpton2016multiple Poor handling and reporting of missing data may result in misleading conclusions and are one of the main reasons for publication rejections.


@gelman2006data hot-deck and matching. Find similar individuals in the dataset (in values of X) and replace with their value of *y*. "non-parametric version of regression" @gelman2006data [p.538] but not sure where this description arises other than assertion that it is useful where (linear) regression is challenging. Similarity can be based on a scoring function, a distance function - but then we'd assume you have scalar numeric or even multi-variate normal data. Another way is to use other variable to create a score for propensity to missingness and then use these values to impute missing. This one doesn't quite make sense and one has to assume it means use propensity score to find the donor cases to then impute missing.

@gelman2006data Routine/Simple multivariate regression imputation is a complicated task and often "off-the-shelf" distribution is used (t for continious and multinomial for categorical). Automated models need additional checks for validity. Iterative uses some starting value for all missing and imputes new values one at a time using all other values (initialised and complete), and iterates until convergence. These methods become more and more complex when modeling non-normal multivariate data, e.g. stratified, clustered, hierarchical etc.

@gelman2006data multiple imputation - replaces each value with several, reflecting uncertainty about the model. here different from prediction tasks and more like a bootstrapped estimation (my words). Common to see 5 imputations, might come from slightly different models, then run a complete analysis on each model. Then average over the parameter estimates. equations on @gelman2006data [p.542] 

King et al (2001) review many of the practical costs and benefits of multiple imputation. 



There are many strategies for recovering from missing data, such as imputation. These are well developed for continuous variables, but sources indicate that there has been much less research for datasets comprising categorical and ordinal variables, (\cite{finch2010imputation}; \cite{leite2010performance}).\newline

@groves2011three has some stuff on weighting models to recover from missingness.  

Furthermore, there is evidence of significant differences in the performance of various imputation strategies over datasets exhibiting different underlying characteristics (\cite{wu2015comparison}; \cite{rodwell2014comparison}; \cite{sim2015missing}). These results indicate a need to take into account not only the model and magnitude of missingness but also other characteristics particular to the target data. For this reason there is real benefit in having a range of imputation methods from which to choose the most suitable in a given situation.\newline


@shrive2006dealing as example of a "self-report" ordinal scale where multiple impute worked best, even for very high rates of missingness. Also one missing response in the whole instrument - makes it a real waste to use listwise deletion.

@he2010missing stat on how many records lost in listwise deletion and good comparison of technique

\cite{carpita2011imputation} describes four categories of  recovery procedures as follows:

@plumpton2016multiple Complete case analysis is appropriate for MCAR but not if missing in covariates or parts of a composite outcome. If MCAR assumption does not hold, the complete case data will not be representative of the underlying population.

### Single Imputation

### Mulitple Imputation

@plumpton2016multiple MI has taken a long time to gain in popularity despite the proven benefits. But there are specific issues with applying it to surveys with multi-item scales. Likert scales are not specifically mentioned but it is safe to assume this specific case is covered by the arguments given.

QUOTED

* a high number of variables
* complexity of the data set
* categorical (non-Normal) variables
* categories with low observed frequency (sparsity in responses)
* questions which are conditional upon previous responses
* and multiple multi-item scales, which are summed (either directly or weighted) during analysis. 
QUOTED

@white2011multiple quoted The unknown missing data are replaced by m independent simulated sets of values drawn from the posterior predictive distribution of the missing data conditional on the observed data. For a single incomplete variable z, this involves constructing an imputation model which regresses z on a set of variables with complete data, say x1,x2,...,xk, among individuals with the observed z

Multiple impute, analyze, combine

@plumpton2016multiple quoted Multiple imputation for a single incomplete variable works by constructing an imputation model relating the incomplete variable to other variables and drawing from the posterior predictive distribution of the missing data conditional on the observed data [1]. The approach allows for uncertainty in the missing data values by introducing variability in the imputed items. In MICE, variables are initially ordered by level of missingness. Missing values are initially replaced for each variable, for example by drawing at random from the observed values of that variable. Imputation is then conducted on each variable sequentially using the observed and currently imputed values of all other variables in the imputation model. In order to stabilise, this imputation step (known as a cycle) is repeated (typically 10 times) to produce one imputed data set. The process is repeated until the desired number of imputed data sets is reached 

@white2011multiple Multiple imputation by chained equations In large data sets it is common for missing values to occur in several variables. Multiple imputation by chained equations (MICE) [9] is a practical approach to generating imputations (MI Stage 1) based on a set of imputation models, one for each variable with missing values. MICE is also known as fully conditional specification [10] and sequential regression multivariate imputation [11]. Initially, all missing values are filled in by simple random sampling with replacement from the observed values. The first variable with missing values, x1 say, is regressed on all other variables x2,...,xk, restricted to individuals with the observed x1. Missing values in x1 are replaced by simulated draws from the corresponding posterior predictive distribution of x1. Then, the next variable with missing values, x2 say, is regressed on all other variables x1,x3,...,xk, restricted to individuals with the observed x2, and using the imputed values of x1. Again, missing values in x2 are replaced by draws from the posterior predictive distribution of x2. The process is repeated for all other variables with missing values in turn: this is called a cycle. In order to stabilize the results, the procedure is usually repeated for several cycles (e.g. 10 or 20) to produce a single imputed data set, and the whole procedure is repeated m times to give m imputed data sets. 

Particular attention to multi-item scales: QUOTED
As missing data in a single item of a multi-item scale leads to a missing total, the rate of missing data in scale totals can be very high. Imputing at the level of scale total whilst ignoring individual items may therefore introduce unnecessary bias.

A recent study considered imputing at item level rather than imputing scale totals [15]. When the pattern of missingness tended towards all items being missing for a respondent, little difference was seen between methods. When the pattern of missingness tended towards individual items being missing, for sample sizes of n > 100, imputing at item level was shown to be more accurate. \

Another study proposed methods for handling multiitem scales at the item score level [16], and further emphasised how mean imputation or single imputation leads to bias and underestimation of standard errors. The study concludes that missing data should be handled by applying multiple imputation to the individual items. 

However, the size and complexity of large survey data can cause complete MI prediction models to fail to converge when the model is specified at item level, rendering the ideal method computationally infeasible.
QUOTED


MI is a maximum likelihood estimation, along with expectation maximization (EM). @plumpton2016multiple MI is robust to departures from normality, small sample sizes and high proportion of missing data. MI also less computationally expensive.

@graham2007many MI and FIML (full information maximum likelihood) are the two most common ways approaches to missing data analysis. MI theory suggest m = 3-5 @graham2007many secondary citation of Schafer and Olsen 1998 and Rubin 1987 gives formula, is enough imputations but @graham2007many suggests this is nowhere near enough. White IR, Royston P, Wood AM secondary citation in @plumpton2016multiple suggests 1 imputation per 1% of missing data. @white2011multiple provides the same rule of thumb arrived at through other logic (go back and get precise) so it should be concluded that this is a very valuable method. The idea of MI is create plausible values through creating m imputations, which also allows a estimates of uncertainty of the estimation to  be reasonably partitioned into within imputation variance which is the usual variance of estimation, and between imputatation variance with is variance attributable to missing data.

@graham2007many has good formulas for calculating the variances properly. These formulas allow fo cases where independent variables are correlated with the missing data, so the fraction of missing information is sometimes less than the fraction of missing data. This fraction of missing information is unreliably estimated unless number of imputations is large. The biggest problem of not having enough imputations is the loss of statistical power compared to conventional wisdom of the subject and is most relevant in situations where accuarately identifying levels of risk is of most importance, such as reduction of risk and prevention science.



## Association Rules

## Classification with Association Rules

## Conceptual Model - Bringing it all together?

A particular characteristic of many surveys is the use of ordinal data and multiple-item (Likert) scales. \cite{huisman1999missing} states that there is a strong relationship between the individual items of a Likert scale which measure one latent trait. Techniques that can recognize this within-instance, structural information and preserve it in the imputed dataset should be valuable. \cite{agrawal1994fast} states that association rules mining uses probabilistic measures (support and confidence) for discovering frequent patterns. Association rules mining algorithms work on discretized or categorical data, such as ordinal, nominal and binary. Furthermore, \cite{chandola2005summarization} describe association rules as a compact model of a dataset and as such may be used to enhance other stages of the analysis. So an association rules-based method for survey data would have several advantages over other imputation methods, yet a search of the literature yields no information on the use of association rules in this context.
