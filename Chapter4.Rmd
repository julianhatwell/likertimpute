# Results

In this section, the following convention will be used to interpret the p-values of statistical tests:

* P > 0.10, No evidence against the null hypothesis. The data appear to be consistent with the null hypothesis.
* 0.05 < P < 0.10, Weak evidence against the null hypothesis in favor of the alternative.
* 0.01 < P < 0.05, Evidence against the null hypothesis.
* 0.001 < P < 0.01, Strong evidence against the null hypothesis.
* P < 0.001, Very strong evidence against the null hypothesis.

Throughout the analysis, the resulting measures were frequently found not to be normally distributed. For consistency, the Kruskall-Wallis test was used rather than ANOVA throughout the write-up to test for significant differences between the means of each group except in stage two, where just two alternatives were being tested the Mann-Whitney-Wilcoxon test was applied.

```{r popstats}
load("wu_stats_pop.RData")
```

```{r graph_setting}
# graph settings
source("C:\\Dev\\Study\\R\\R_Themes\\MarketingTheme.R")
MyTempTheme <- MyLatticeTheme
MyTempTheme$superpose.symbol$col <- myPal
MyTempTheme$add.line$col <- myPalDark[3]
```

This section contains the tabulated results and vizualisations of the benchmarking experiments. In the interests of brevity, only selected results highlighting the key findings will be included in this report.

## Stage 1: Rules Selection Method - No Default

The purpose of stage 1 is to ascertain which rule selection method performs best and eliminate the worst performers. In all cases the rules were sorted by confidence from best to worst. These methods have no default class setting and their output must undergo a list-wise deletion prior to further analysis.

The following coding is used:

* bestrule: The single best rule is selected and its consequent is applied. Equivalent to Top N for N = 1.

* topnm, topnm3, topnm7: The top N rules are found and their consequents are pooled. If no number is given, all the found rules are used. The mean is taken and non-deterministically (nd) rounded, see \@ref(eq:pmimp) to \@ref(eq:twimp) for details on nd rounding.

* topnmjv, topnmjv3, topnmjv7: The top N rules are found and their consequents are pooled as above. Imputation is by majority vote. In case of a tie, a random value is taken from the tied values.

* rhsfreq, rhsfreq3, rhsfreq7: The top N rules are found and their consequents are pooled as above. A random value is drawn from their frequency distribution.

### Symmetric Data

```{r rs_wu_sym_load_data}
load("rs_wu_sym_results.RData")

res <- rs_wu_sym_results

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))

dtsts <- unique(res$results$dataset)
```

#### Mean Absolute Scale Errors

```{r rs-wu-sym-plots-mase, fig.height=3, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-mase-A-aov-dtsts-plots, fig.cap=paste("Density Plots of the", sts, "statistic by dataset. The density curves for the variants at each level of dataset (not shown) also show non-normality. Shapiro-Wilk tests (not shown) confirmed the visual assessment."), fig.height=2}
MyResTheme <- MyLatticeTheme
MyResTheme$plot.line$col <- myPal[7]
MyResTheme$plot.symbol$col <- myPal[7]
MyResTheme$plot.symbol$pch <- 1
dplot <- list()
for (ds in dtsts) {
  dplot[[ds]] <- with(aov_data, 
    densityplot(~aov_data$value[dataset == ds]
                , xlab = ds
                , par.settings = MyResTheme
                , scales = MyLatticeScale)
    )
}

do.call(grid.arrange, args = list(grobs = dplot, nrow = 1))
```

There is very strong evidence of non-normality for the dataset and variant effects, so the Kruskall-Wallis test is chosen to test for significant differences between groups. See Figure \@ref(fig:rs-wu-sym-mase-A-aov-dtsts-plots).

```{r rs-wu-sym-mase-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

The Kruskall-Wallis test finds very strong evidence of a difference in MASE for Scale A between datasets. Figure \@ref(fig:rs-wu-sym-plots-mase) appears to show that the bias in each dataset from smallest to largest was MCAR, MNAR then MAR. This was confirmed with a Tukey's HSD test (not shown). There was no evidence of a difference between the individual method variants for this statistic. 

```{r rs-wu-sym-mase-A, results='asis', eval=FALSE}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_A"
         , c("dataset", "variant", "mean", "st_err"))
mase_A <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale A.")

mase_A
```

```{r rs-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-mase-B-aov-dtsts-plots, fig.cap=paste("Density Plots of the", sts, "statistic by dataset. The density curves for the variants at each level of dataset (not shown) also show non-normality. Shapiro-Wilk tests (not shown) confirmed the visual assessment."), fig.height=2}
MyResTheme <- MyLatticeTheme
MyResTheme$plot.line$col <- myPal[7]
MyResTheme$plot.symbol$col <- myPal[7]
MyResTheme$plot.symbol$pch <- 1
dplot <- list()
for (ds in dtsts) {
  dplot[[ds]] <- with(aov_data, 
    densityplot(~aov_data$value[dataset == ds]
                , xlab = ds
                , par.settings = MyResTheme
                , scales = MyLatticeScale)
    )
}

do.call(grid.arrange, args = list(grobs = dplot, nrow = 1))
```

There is very strong evidence of non-normality for the dataset and variant effects, so the Kruskall-Wallis test is chosen to test for significant differences between groups. See Figure \@ref(fig:rs-wu-sym-mase-B-aov-dtsts-plots).

```{r rs-wu-sym-mase-B-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

The Kruskall-Wallis test finds very strong evidence of a difference in MASE for Scale A between datasets. A Tukey's HSD test (not shown) confirmed the visual assessment of Figure \@ref(fig:rs-wu-sym-plots-mase) that the bias is least for MCAR data, with no significant difference between the other two datasets. Again, there is no evidence of a difference between the method variants for the MASE Scale B statistic.

```{r rs-wu-sym-mase-B, results='asis', eval=FALSE}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_B"
         , c("dataset", "variant", "mean", "st_err"))
mase_B <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale B.")

mase_B
```

#### Individual Item Means

```{r rs-wu-sym-plots-mean, fig.height=3, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sym-mean-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                         , subset = aov_data$dataset == ds
                         , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

The Kruskal-Wallis test finds weak evidence to suggest a significant difference in mean individual item scores for Scale A between datasets but the Tukey's HSD test, which has a more conservative evidence requirement does not confirm the visual assessment that estimates for MAR data in Scale A were lower than for the other two datasets. Figure \@ref(fig:rs-wu-sym-plots-mean) shows a similar pattern in Scale B with MCAR estimates appearing slightly lower. However, a Kruskall-Wallis test (not shown) does not provide sufficient evidence against the null hypothesis.

The Kruskall-Wallis tests also found no evidence of any difference between the method variants. Nevertheless, there does appear to be a well defined pattern, in both plots of Figure \@ref(fig:rs-wu-sym-plots-mean), indicating that the estimated values for the majority vote methods were slightly lower. This is not statistically significant with an experimental sample size of just 100.

```{r rs-wu-sym-mean-A, results='asis', eval=FALSE}
tab <- subset(res$qdata
         , res$qdata$stats == "mean_A"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))
mean_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("Mean Scale A after imputation. Population value (before) was", round(pop$mean_A, 5)))

mean_A
```

```{r rs-wu-sym-mean-B, results='asis', eval=FALSE}
tab <- subset(res$qdata
         , res$qdata$stats == "mean_B"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))
mean_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("Mean Scale B after imputation. Population value (before) was", round(pop$mean_B, 5)))

mean_B
```

#### Individual Item Standard Deviations

```{r rs-wu-sym-plots-sd, fig.height=3, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sym-sd-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

There is very strong evidence of a difference in individual item standard deviations scores for Scale A between datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown).

```{r rs-wu-sym-sd-A, results='asis', eval=FALSE}
tab <- subset(res$qdata
         , res$qdata$stats == "sd_A"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))
sd_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("St.Dev of Scale A after imputation. Population value (before) was", round(pop$sd_A, 5)))

sd_A
```

```{r rs-wu-sym-sd-B, results='asis', eval=FALSE}
tab <- subset(res$qdata
         , res$qdata$stats == "sd_B"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))

sd_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("St.Dev of Scale B after imputation. Population value (before) was", round(pop$sd_B, 5)))

sd_B
```

#### Cronbach's alpha

```{r rs-wu-sym-plots-alpha, fig.height=3, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sym-alpha-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

```{r rs-wu-sym-alpha-A-tuk}
aov_res <- aov(value~dataset, data = aov_data)
THSD <- TukeyHSD(aov_res)
print("Adjusted p-values for Tukey's HSD test of difference in means")
THSD$dataset[, "p adj"]
```

There is very strong evidence to suggest a difference in Cronbach's for Scale A between datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown). A Tukey's HSD test supports the visual assessment that estimates of Cronbach's alpha were significantly different between the three datasets, with the highest estimates given in MNAR data, followed by MCAR and MAR.

```{r rs-wu-sym-alpha-A, results='asis', eval=FALSE}
tab <- subset(res$qdata
, res$qdata$stats == "alpha_A"
, c("dataset", "variant", "mean", "st_err", "rel_bias"))
alpha_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
, digits = 5
, row.names = FALSE
, caption = paste("Cronbach's alpha of Scale A after imputation. Population value (before) was", round(pop$alpha_A, 5)))

alpha_A
```

```{r rs-wu-sym-alpha-B, results='asis', eval=FALSE}
tab <- subset(res$qdata
, res$qdata$stats == "alpha_B"
, c("dataset", "variant", "mean", "st_err", "rel_bias"))
alpha_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
, digits = 5
, row.names = FALSE
, caption = paste("Cronbach's alpha of Scale B after imputation. Population value (before) was", round(pop$alpha_B, 5)))

alpha_B
```

#### Split-half Correlation

```{r rs-wu-sym-plots-splith, fig.height=3, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-splith-aov-dtsts-plots, fig.cap=paste("Density Plots of the", sts, "statistic by dataset. The density curves for the variants at each level of dataset (not shown) also show non-normality. Shapiro-Wilk tests (not shown) confirmed the visual assessment."), fig.height=2}
MyResTheme <- MyLatticeTheme
MyResTheme$plot.line$col <- myPal[7]
MyResTheme$plot.symbol$col <- myPal[7]
MyResTheme$plot.symbol$pch <- 1
dplot <- list()
for (ds in dtsts) {
  dplot[[ds]] <- with(aov_data, 
    densityplot(~aov_data$value[dataset == ds]
                , xlab = ds
                , par.settings = MyResTheme
                , scales = MyLatticeScale)
    )
}

do.call(grid.arrange, args = list(grobs = dplot, nrow = 1))
```

There is very strong evidence of non-normality for the dataset and variant effects, so the Kruskall-Wallis test is chosen to test for significant differences between groups. See Figure \@ref(fig:rs-wu-sym-splith-aov-dtsts-plots).

```{r rs-wu-sym-split-h-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

```{r rs-wu-sym-split-h-tuk}
aov_res <- aov(value~dataset, data = aov_data)
THSD <- TukeyHSD(aov_res)
print("Adjusted p-values for Tukey's HSD test of difference in means")
THSD$dataset[, "p adj"]
```

The Kruskall-Wallis test finds very strong evidence of a difference in the split half correlation between datasets. Figure \@ref(fig:rs-wu-sym-plots-splith) appears to show that the bias in each dataset from smallest to largest was MNAR, MAR then MCAR. This was confirmed with a Tukey's HSD test. There was no evidence of a difference between the individual method variants for this statistic. 

#### Ability

```{r rs-wu-sym-ability-attr-aov-dtsts}
sts <- "ability_attr"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-ability-attr-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

```{r rs-wu-sym-ability-case-aov-dtsts}
sts <- "ability_case"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-ability-case-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

These results show very strong evidence of a difference in the ability by attribute (data point) and case between datasets. This was confirmed with a Tukey's HSD test (not shown). Tables \@ref(tab:rs-wu-sym-ability-attr) and \@ref(tab:rs-wu-sym-ability-case) show the fully tabulated results. There was no evidence of a difference between the individual method variants for this statistic. 

```{r rs-wu-sym-ability-attr, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_attr"
, c("dataset", "variant", "mean", "st_err"))

ability_attr <- knitr::kable(tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by attributes")

ability_attr
```

```{r rs-wu-sym-ability-case, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_case"
, c("dataset", "variant", "mean", "st_err")) 
ability_case <- knitr::kable(
tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by cases")

ability_case
```

```{r rs-ability-vim-plot1, fig.height=2.25, fig.cap='VIM diagnostic plot showing patterns of missingness remaining after imputation for the best rule variant. Showing only the variables that were subject to missingness and imputation.'}
load("sample_results1.RData")
aggr_plot <- aggr(sample_results1$wu_sasym_MCAR_0.3_1000$bestrule[, c(1:3, 7:9)]
                  , col = c(myPalDark[3]
                            , myPal[4])
                  , numbers = TRUE
                  , sortVars = TRUE
                  , labels = names(sample_results1$wu_sasym_MCAR_0.3_1000$bestrule[, c(1:3, 7:9)])
                  , cex.axis = .7
                  , gap = 3
                  , ylab = c("Histogram of missing data","Pattern"))
```

```{r rs-ability-vim-plot2, fig.height=2, fig.cap='VIM diagnostic plot showing patterns of missingness remaining after imputation for the rhs frequency variant. Showing only the variables that were subject to missingness and imputation.'}
aggr_plot <- aggr(sample_results1$wu_sasym_MCAR_0.3_1000$rhsfreq[, c(1:3, 7:9)]
                  , col = c(myPalDark[3]
                            , myPal[4])
                  , numbers = TRUE
                  , sortVars = TRUE
                  , labels = names(sample_results1$wu_sasym_MCAR_0.3_1000$rhsfreq[, c(1:3, 7:9)])
                  , cex.axis = .7
                  , gap = 3
                  , ylab = c("Histogram of missing data","Pattern"))
```

The ability results are also confirmed with a diagnostic plot from the VIM package. This reveals that the remaining pattern of missingness is the same for all the variants. It is not surprising because they all use the same ruleset, which is discovered deterministically by the *apriori* algorithm. See Figures \@ref(fig:rs-ability-vim-plot2) and \@ref(fig:rs-ability-vim-plot2).

\clearpage

### Severely Asymmetric Data

```{r rs_wu_sasym_load_data}
load("rs_wu_sasym_results.RData")

res <- rs_wu_sasym_results

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))

dtsts <- unique(res$results$dataset)
```

#### Mean Absolute Scale Errors

```{r rs-wu-sasym-plots-mase, fig.height=3, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-mase-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}

```

```{r rs-wu-sasym-mase-A-tuk}
aov_res <- aov(value~dataset, data = aov_data)
THSD <- TukeyHSD(aov_res)
print("Adjusted p-values for Tukey's HSD test of difference in means")
THSD$dataset[, "p adj"]
```

These results show very strong evidence of a difference in MASE for Scale A between datasets. Figure \@ref(fig:rs-wu-sasym-plots-mase) appears to show that the bias in each dataset from smallest to largest was MCAR, MNAR then MAR. This was confirmed with a Tukey's HSD test (not shown). There was no evidence of a difference between the individual method variants for this statistic. Scale B results followed the same pattern (not shown).

#### Individual Item Means

```{r rs-wu-sasym-plots-mean, fig.height=3, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sasym-mean-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

There is very strong evidence of a significant difference in mean individual item scores for Scale A between datasets. A Tukey's HSD test (not shown) confirmed the visual assessment that estimates for MAR data in Scale A were higher than for the other two datasets. There was no evidence of any difference between the mean estimates for individual items of Scale B (not shown). The Kruskall-Wallis tests also found no evidence of any difference between the method variants.

#### Individual Item Standard Deviations

```{r rs-wu-sasym-plots-sd, fig.height=3, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sasym-sd-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

There is very strong evidence of a difference in individual item standard deviations scores for Scales A datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown).

#### Cronbach's alpha

```{r rs-wu-sasym-plots-alpha, fig.height=3, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sasym-alpha-A-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

There is very strong evidence to suggest a difference in Cronbach's for Scale A between datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown).

#### Split-half Correlation

```{r rs-wu-sasym-plots-splith, fig.height=3, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-split-h-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

These results show very strong evidence of a difference in the split half correlation between datasets. Figure \@ref(fig:rs-wu-sasym-plots-splith) appears to show that the bias in each dataset from smallest to largest was MNAR, MAR then MCAR. This was confirmed with a Tukey's HSD test (not shown). There was no evidence of a difference between the individual method variants for this statistic. 

#### Ability

```{r rs-wu-sasym-ability-attr-aov-dtsts}
sts <- "ability_attr"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-ability-attr-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

```{r rs-wu-sasym-ability-case-aov-dtsts}
sts <- "ability_case"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-ability-case-aov, results='asis'}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
print(kw_res)
```

These results show very strong evidence of a difference in the ability by attribute (data point) and case between datasets. This was confirmed with a Tukey's HSD test (not shown). Tables \@ref(tab:rs-wu-sasym-ability-attr) and \@ref(tab:rs-wu-sasym-ability-case) show the fully tabulated results. There was no evidence of a difference between the individual method variants for this statistic. 

```{r rs-wu-sasym-ability-attr, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_attr"
, c("dataset", "variant", "mean", "st_err"))

ability_attr <- knitr::kable(tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by attributes")

ability_attr
```

```{r rs-wu-sasym-ability-case, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_case"
, c("dataset", "variant", "mean", "st_err")) 
ability_case <- knitr::kable(
tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by cases")

ability_case
```

\clearpage

## Stage 2: Rule Selection - Default Class Methods

For this stage, a final round of imputation will be applied to any data points for which no useful rule could be found. Two default class methods are compared.

1. Majority Class: After the initial round of AR-based imputations, the distribution is tabulated and the most frequent class is used. In the event of a tie, a random value is taken from the tied values.

1. Non-determistic: After the initial round of AR-based imputations, the distribution is tabulated and used as a posterior distribution. A random draw is taken from this distribution for each remaining missing value.

As these methods leave no remaining missing variables, the Ability statistics will not be measured. Also, the difference in performance between the datasets was established in the previous stage and will not be commented on further.

### Symmetric Data

```{r dc_wu_sym_load_data}
load("dc_wu_sym_results.RData")

res <- dc_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r dc-wu-sym-plots-mase, fig.height=1.5, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r dc-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

These results show very strong evidence of a difference in MASE for Scales A and B between the variants. Figure \@ref(fig:dc-wu-sym-plots-mase) shows that variant 1 has the smaller bias. See also Tables \@ref(tab:dc-wu-sym-mase-A) and \@ref(tab:dc-wu-sym-mase-B) 

```{r dc-wu-sym-mase-A, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_A"
         , c("dataset", "variant", "mean", "st_err"))
mase_A <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale A.")

mase_A
```

```{r dc-wu-sym-mase-B, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_B"
         , c("dataset", "variant", "mean", "st_err"))
mase_B <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale B.")

mase_B
```

#### Individual Item Means

```{r dc-wu-sym-plots-mean, fig.height=1.5, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-mean-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r dc-wu-sym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-mean-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There is no evidence of any difference between the two variants for individual item mean of either Scale A or B.

#### Individual Item Standard Deviations

```{r dc-wu-sym-plots-sd, fig.height=1.5, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-sd-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r dc-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There is strong evidence in the MCAR case, and evidence in MAR and MNAR cases of a difference in individual item standard deviations scores for Scale A, and a similar but not identical pattern in Scale B. A visual assessment of Figure \@ref(fig:dc-wu-sym-plots-sd) shows that variant 2 has the smaller bias. See Tables \@ref(tab:dc-wu-sym-sd-A) and \@ref(tab:dc-wu-sym-sd-B) for the tabulated results.

```{r dc-wu-sym-sd-A, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "sd_A"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))
sd_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("St.Dev of Scale A after imputation. Population value (before) was", round(pop$sd_A, 5)))

sd_A
```

```{r dc-wu-sym-sd-B, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "sd_B"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))

sd_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("St.Dev of Scale B after imputation. Population value (before) was", round(pop$sd_B, 5)))

sd_B
```

#### Cronbach's alpha

```{r dc-wu-sym-plots-alpha, fig.height=1.5, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-alpha-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r dc-wu-sym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-alpha-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There is very strong evidence to suggest a difference in Cronbach's for Scale A and at least evidence at the 0.05 level or less for Scale B between the variants. A visual assessment of Figure \@ref(fig:dc-wu-sym-plots-alpha) shows that variant 1 has the smaller bias. See Tables \@ref(tab:dc-wu-sym-alpha-A) and \@ref(tab:dc-wu-sym-alpha-B) for the tabulated results.

```{r dc-wu-sym-alpha-A, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "alpha_A"
, c("dataset", "variant", "mean", "st_err", "rel_bias"))
alpha_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
, digits = 5
, row.names = FALSE
, caption = paste("Cronbach's alpha of Scale A after imputation. Population value (before) was", round(pop$alpha_A, 5)))

alpha_A
```

```{r dc-wu-sym-alpha-B, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "alpha_B"
, c("dataset", "variant", "mean", "st_err", "rel_bias"))
alpha_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
, digits = 5
, row.names = FALSE
, caption = paste("Cronbach's alpha of Scale B after imputation. Population value (before) was", round(pop$alpha_B, 5)))

alpha_B
```

#### Split-half Correlation

```{r dc-wu-sym-plots-splith, fig.height=1.5, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sym-split-h-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There is no evidence of a difference in the split half correlation between the two variants.

\clearpage

### Severely Asymmetric Data

```{r dc_wu_sasym_load_data}
load("dc_wu_sasym_results.RData")

res <- dc_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r dc-wu-sasym-plots-mase, fig.height=1.5, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sasym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r dc-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sasym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There was no evidence of a difference in MASE for Scales A between the two variants. For Scale B, there was very strong evidence exept in the MAR case, where there was none. Figure \@ref(fig:dc-wu-sasym-plots-mase) shows that variant 1 has the smaller bias in the case of Scale B. See also Table  \@ref(tab:dc-wu-sasym-mase-B).

```{r dc-wu-sasym-mase-B, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_B"
         , c("dataset", "variant", "mean", "st_err"))
mase_B <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale B.")

mase_B
```

#### Individual Item Means

```{r dc-wu-sasym-plots-mean, fig.height=1.5, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Mann-Whitney-Wilcoxon test (not shown) found no evidence of any difference between the two variants for individual item mean of either Scale A or B.

#### Individual Item Standard Deviations

```{r dc-wu-sasym-plots-sd, fig.height=1.5, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Mann-Whitney-Wilcoxon test (not shown) found no evidence of any difference between the two variants for individual item standard deviations for either Scale A or B.

#### Cronbach's alpha

```{r dc-wu-sasym-plots-alpha, fig.height=1.5, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Mann-Whitney-Wilcoxon test (not shown) found no evidence of any difference between the two variants for individual item standard deviations for either Scale A or B.

#### Split-half Correlation

```{r dc-wu-sasym-plots-splith, fig.height=1.5, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

There is no evidence of a difference in the split half correlation between the two variants.

\clearpage

## Stage 3: Interestingness Measures

For this stage, *Confidence*, La Place Prediction Accuracy, Chi Square and Weighted Chi Square are compared to determine if any has a positive effect on performance.

### Symmetric Data

```{r im_wu_sym_load_data}
load("im_wu_sym_results.RData")

res <- im_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r im-wu-sym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

The Kruskall-Wallis test (not shown) did not find any evidence of significant differences between the variants.

#### Individual Item Means

```{r im-wu-sym-plots-mean, fig.height=2, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Kruskall-Wallis test (not shown) found no evidence of any difference between the variants for individual item mean of either Scale A or B.

#### Individual Item Standard Deviations

```{r im-wu-sym-plots-sd, fig.height=2, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sym-sd-B-tuk}
for (ds in dtsts[2:3]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

A Kruskall-Wallis test (not shown) found no evidence of a difference in means of the individual item standard deviations for Scale A. However, for Scale B, there is weak evidence of a difference in individual item standard deviations for dataset MAR and evidence for dataset MNAR. A visual assessment of Figure \@ref(fig:im-wu-sym-plots-sd) suggests that Chi squared and weighted Chi squared are slightly ahead of the other two but a Tukey's HSD test is not conclusive.

#### Cronbach's alpha

```{r im-wu-sym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

The Kruskall-Wallis (not shown) test finds no evidence of difference in Cronbach's alpha for eaither Scales A and B between the variants.

#### Split-half Correlation

```{r im-wu-sym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

The Kruskall-Wallis (not shown) test finds no evidence of difference in Cronbach's alpha for eaither Scales A and B between the variants.

\clearpage

### Severely Asymmetric Data

```{r im_wu_sasym_load_data}
load("im_wu_sasym_results.RData")

res <- im_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r im-wu-sasym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r im-wu-sasym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-mase-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r im-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r im-wu-sasym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-mase-B-tuk}
for (ds in dtsts[2:3]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for Scale A between the variants. Also, for Scale B, there was weak evidence in the MAR and MNAR cases. Figure \@ref(fig:im-wu-sasym-plots-mase) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this, at least in the Scale A case.

#### Individual Item Means

```{r im-wu-sasym-plots-mean, fig.height=2, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Kruskall-Wallis test (not shown) found no evidence of any difference among the variants between the individual item mean of either Scale A or B.

#### Individual Item Standard Deviations

```{r im-wu-sasym-plots-sd, fig.height=2, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-sd-A-aov, eval=TRUE}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-sd-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r im-wu-sasym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-sd-B-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in individual item standard deviations for Scale A between the variants. Also, for Scale B, there was weak evidence in the MAR case. Figure \@ref(fig:im-wu-sasym-plots-sd) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this.

#### Cronbach's alpha

```{r im-wu-sasym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-alpha-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-alpha-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r im-wu-sasym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-alpha-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There was very strong evidence of a difference in individual item standard deviations for Scale A between the variants. Also, for Scale B, there was weak evidence in the MAR case. Figure \@ref(fig:im-wu-sasym-plots-sd) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this for Scale A.

#### Split-half Correlation

```{r im-wu-sasym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r im-wu-sasym-split-h-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-split-h-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in individual item standard deviations for Scale A between the variants. Also, for Scale B, there was weak evidence in the MAR case. Figure \@ref(fig:im-wu-sasym-plots-sd) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this for Scale A and gives a borderline reseult for Scale B MAR.

\clearpage

## Stage 4: Variants

This stage compares the basic single, all at once imputation with variants based on the sequential-iterative process (modeled on MICE), propensity scoring and feature engineering with precalculated scale means.  The following coding is used:
  
1. bestdc1chi: All other variants are extended from this base which uses best rule by Chi square precedence.
1. bestdc1chico: The dataset is extended by the addition of a co-variates for each item of the multi-item scale which is calculated as the mathematically rounded mean of the scale excluding that individual item. Minimum support is adjusted upwards to account for the larger number of variables but this still adds considerable time and complexity to the process.
1. ibestdc1chi: As above but the imputation is performed sequentially and iteratively one variable at a time. A new set of CARs is generated for every step.
1. ibestdc1chico: As above, the sequential-iterative variant for the extended dataset.
1. ibestdc1chip: Between each sequential step, a logistic regression of the next variable in the sequence onto all the other variables is calculated and the predicted probability, or propensity for missingness is used to rank and split the dataset into two evenly sized subsets. The imputation steps are carried out separately on each split.
1. ibestdc1chipco: As above, for the extended dataset.

### Symmetric Data

```{r vr_wu_sym_load_data}
load("vr1_wu_sym_results.RData")

res <- vr_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r vr-wu-sym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-mase-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-mase-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants. A visual assessment indicates that ibestdc1chico is well ahead in both cases but no separation between several others in joint second place. This is confirmed by Tukey's HSD test. See Figure \@ref(fig:vr-wu-sym-plots-mase).

#### Individual Item Means

```{r vr-wu-sym-plots-mean, fig.height=2, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-mean-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-mean-A-tuk}
for (ds in dtsts[1:2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-mean-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

The Kruskall-Wallis test found evidence of a difference in individual item means but only for the MCAR and MAR cases in scale A but the Tukey's HSD test does not confirm this because of the more conservative evidence requirements. There is no evidence of any difference for Scale B individual item means. See Figure \@ref(fig:vr-wu-sym-plots-mean).

#### Individual Item Standard Deviations

```{r vr-wu-sym-plots-sd, fig.height=2, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-sd-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-sd-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-sd-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in individual item standard deviations for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sym-plots-sd) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chip and ibestdc1chipco are joint leaders.

#### Cronbach's alpha

```{r vr-wu-sym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-alpha-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-alpha-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-alpha-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-alpha-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sym-plots-mean) shows a nuanced result where ibestdc1chip, ibestchipco and ibestchico take the lead for different combinations of Scale and dataset.

#### Split-half Correlation

```{r vr-wu-sym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sym-split-h-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sym-split-h-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found strong (MCAR) to very strong evidence (MAR, MNAR) of a difference in split half correlation between the variants which is confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sym-plots-mean) shows a nuanced result, and for the first time one of the variants ibestdc1chip actually over-estimates the population parameter. To this point, the parameters have always been biased downwards.

### Severely Asymmetric Data

```{r vr_wu_sasym_load_data}
load("vr1_wu_sasym_results.RData")

res <- vr_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r vr-wu-sasym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sasym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-mase-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sasym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-mase-B-tuk}
for (ds in dtsts[2:3]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants which are confirmed by Tukey's HSD test. However, the variants with the smallest bias are different in each case, as can be seen in Figure \@ref(fig:vr-wu-sasym-plots-mase). For Scale A, ibestdc1chip is ahead of the others for all datasets but the same variant has not performed so well on Scale B.

#### Individual Item Means

```{r vr-wu-sasym-plots-mean, fig.height=2, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-mean-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-mean-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There was very strong evidence of a difference in individual item means for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-mean) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chipco does even better.

#### Individual Item Standard Deviations

```{r vr-wu-sasym-plots-sd, fig.height=2, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-sd-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-sd-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sasym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-sd-B-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in individual item standard deviations for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-sd) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chipco does even better.

#### Cronbach's alpha

```{r vr-wu-sasym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-alpha-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-alpha-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sasym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-alpha-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

There was very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-mean) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chipco does even better while ibestdc1chico comes second for MAR data. Important to note that the latter did worst of all for Scale A mean and standard deviation.

#### Split-half Correlation

```{r vr-wu-sasym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sasym-split-h-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r vr-wu-sasym-split-h-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in split half correlation between the variants which is confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-mean) shows ibestdc1chip ahead of the others for all datasets.

\clearpage

## Stage 5: Benchmarks

The best performing variant of the novel AR-based imputation (ibestdc1chip) method is run as a multiple imputation, i.e. it is run to convergence m \footnote{m = 5 for the MI techniques in this section.} times. The final estimates are made using Rubin's rules to combine the m imputed datasets. The results are compared with the following benchmark techniques:
  
1. PM: Person mean imputation. See \@ref(eq:personmean) and \@ref(eq:pmimp).
1. CIM: Corrected item mean imputation. See \@ref(eq:personmean) to \@ref(eq:personitemmean) and \@ref(eq:cimimp).
1. TW: Two-way imputation. See \@ref(eq:personmean) to \@ref(eq:totalmean) and \@ref(eq:twimp).
1. ICS: Item correlation substitution. See \@ref(eq:icsimp).
1. amelia: Multiple Imputation by expectation maximization with bootstrapping, as implemented in the Amelia II package, @R-Amelia. See \secref{sec:singimp} for further details.
1. mice: Multiple Imputation with Chained Equations, as implemented in the mice package, @R-mice. See \secref{sec:singimp} for further details.

### Symmetric Data

```{r bm_wu_sym_load_data}
load("bm1_wu_sym_results.RData")

res <- bm_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r bm-wu-sym-plots-mase, fig.height=2.25, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-mase-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-mase-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants. A visual assessment indicates that ibestdc1chico has outperformed the benchmark MI techniques. However, the single imputation techniques perform somewhat better here with no clear leader. This is confirmed by Tukey's HSD test. See Figure \@ref(fig:bm-wu-sym-plots-mase).

#### Individual Item Means

```{r bm-wu-sym-plots-mean, fig.height=2.25, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-mean-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-mean-A-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-mean-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-mean-B-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found strong evidence of a difference in individual item means for both Scales A and B but only for the MAR case. The Tukey's HSD test found that the difference was only detectable between PM and the other single imputation techniques and does not impact on this research. See Figure \@ref(fig:bm-wu-sym-plots-mean).

#### Individual Item Standard Deviations

```{r bm-wu-sym-plots-sd, fig.height=2.25, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-sd-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-sd-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-sd-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in individual item standard deviations for both Scales A and B between the variants. Tukey's HSD test confirm the visual assessment that ibestdc1chip underperformed in all three datasets for Scale B but the results for Scale A were more nuanced. Nevertheless, good performance in the MNAR case is perhaps offset by the lack of consistency and it would be fair to say that the novel method is the worst performer against this measure. See Figure \@ref(fig:bm-wu-sym-plots-sd).

#### Cronbach's alpha

```{r bm-wu-sym-plots-alpha, fig.height=2.25, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-alpha-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-alpha-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-alpha-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-alpha-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. The results are very nuanced and worth considering further. All the single imputation methods tended to bias the alpha statistic upwards by around two percentage points, while ibestdc1chip and amelia tended towards a downward bias of a smaller magnitude. ibestdc1chip beat amelia in the MCAR and MNAR cases. Overall mice was the best performer for this measure, returning an estimate with no detectable difference from the population parameter.  See Figure \@ref(fig:bm-wu-sym-plots-mean).

#### Split-half Correlation

```{r bm-wu-sym-plots-splith, fig.height=2.25, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sym-split-h-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sym-split-h-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. The upwards bias in the estimates from the single imputation techniques on this statistic is rather startling. It appears to be so great that the two Scales would be considered to be associated in any test of reliability. This is very serious consequences for subsequent data analysis. ibestdc1chip compares very favourably with mice and amelia. All three very closely preserve the population parameter. See Figure \@ref(fig:bm-wu-sym-plots-splith).

\clearpage

### Severely Asymmetric Data

```{r bm_wu_sasym_load_data}
load("bm1_wu_sasym_results.RData")

res <- bm_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r bm-wu-sasym-plots-mase, fig.height=2.25, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sasym-mase-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-mase-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sasym-mase-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-mase-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants. A visual assessment indicates that ibestdc1chico outperformed the benchmark MI techniques for Scale B but was the worst performer for Scale A. As with the symmetric data, the single imputation techniques perform somewhat better here with no clear leader, although PM was the worst of these. This is confirmed by Tukey's HSD test. See Figure \@ref(fig:bm-wu-sasym-plots-mase).

#### Individual Item Means

```{r bm-wu-sasym-plots-mean, fig.height=2.25, fig.cap='Mean Scale Scores after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-mean-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-mean-A-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-mean-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-mean-B-tuk}
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found strong evidence of a difference in individual item means for both Scales A and B. This is confirmed by the Tukey's HSD test. The visual assessment shows the AR-based imputation performing worst of all in both scales. See Figure \@ref(fig:bm-wu-sasym-plots-mean).

#### Individual Item Standard Deviations

```{r bm-wu-sasym-plots-sd, fig.height=2.25, fig.cap='Scale Score standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-sd-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-sd-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-sd-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-sd-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in individual item standard deviations for both Scales A and B between the variants. Tukey's HSD test confirm the visual assessment that ibestdc1chip underperformed in all three datasets for Scale B but the results for Scale A were more nuanced. Nevertheless, good performance in the MNAR case is perhaps offset by the lack of consistency and it would be fair to say that the novel method is the worst performer against this measure. See Figure \@ref(fig:bm-wu-sasym-plots-sd).

#### Cronbach's alpha

```{r bm-wu-sasym-plots-alpha, fig.height=2.25, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-alpha-A-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-alpha-A-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-alpha-B-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-alpha-B-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. The results are very nuanced and worth considering further. All the single imputation methods tended to bias the alpha statistic upwards by around two percentage points, while ibestdc1chip and amelia tended towards a downward bias of a smaller magnitude. ibestdc1chip beat amelia in the MCAR and MNAR cases. Overall mice was the best performer for this measure, returning an estimate with no detectable difference from the population parameter.  See Figure \@ref(fig:bm-wu-sasym-plots-mean).

#### Split-half Correlation

```{r bm-wu-sasym-plots-splith, fig.height=2.25, fig.width=4.5, fig.cap='Split half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value before imputation.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sasym-split-h-aov, results='asis'}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r bm-wu-sasym-split-h-tuk}
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print("Adjusted p-values for Tukey's HSD test of difference in means")
  print(paste("Dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskall-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. The upwards bias in the estimates from the single imputation techniques on this statistic is rather startling. It appears to be so great that the two Scales would be considered to be associated in any test of reliability. This is very serious consequences for subsequent data analysis. ibestdc1chip compares very favourably with mice and amelia. All three very closely preserve the population parameter. See Figure \@ref(fig:bm-wu-sasym-plots-splith).

\clearpage