# Results

In this section, the following convention will be used to interpret the p-values of statistical tests:

* P > 0.10, No evidence against the null hypothesis.
* 0.05 < P < 0.10, Weak evidence against the null hypothesis in favor of the alternative.
* 0.01 < P < 0.05, Evidence against the null hypothesis.
* 0.001 < P < 0.01, Strong evidence against the null hypothesis.
* P < 0.001, Very strong evidence against the null hypothesis.

Throughout the analysis, the statistics measured were frequently found not to be normally distributed, even within groups. For consistency, the Kruskal-Wallis test was used throughout the write-up, rather than ANOVA, to test for significant differences between the means of each group except in stage two, where just two alternatives were being tested the Mann-Whitney-Wilcoxon test was applied. In the interests of brevity, only selected results highlighting the key findings will be included in this report.

```{r popstats}
load("wu_stats_pop.RData")
```

```{r graph_setting}
# graph settings
source("C:\\Dev\\Study\\R\\R_Themes\\MarketingTheme.R")
MyTempTheme <- MyLatticeTheme
MyTempTheme$superpose.symbol$col <- myPal
MyTempTheme$add.line$col <- myPalDark[3]
```

## Stage 1: Rules Selection Method - No Default

The purpose of stage 1 was to ascertain which rule selection methods perform best. In all cases the rules were sorted by confidence from best to worst. These methods have no default class setting and their output must undergo a list-wise deletion prior to further analysis.

The following coding is used:

* bestrule: The single best rule is selected and its consequent is applied. Equivalent to Top N for N = 1.

* topnm, topnm3, topnm7: The top N rules are found and their consequents are pooled. If no number is given, all the found rules are used. The mean is taken and non-deterministically (nd) rounded, see \@ref(eq:pmimp) to \@ref(eq:twimp) for details on nd rounding.

* topnmjv, topnmjv3, topnmjv7: The top N rules are found and their consequents are pooled as above. Imputation is by majority vote. In case of a tie, a random value is taken from the tied values.

* rhsfreq, rhsfreq3, rhsfreq7: The top N rules are found and their consequents are pooled as above. A random value is drawn from their frequency distribution.

### Symmetric Data

```{r rs_wu_sym_load_data}
load("rs_wu_sym_results.RData")

res <- rs_wu_sym_results

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))

dtsts <- unique(res$results$dataset)
```

#### Mean Absolute Scale Errors

```{r rs-wu-sym-plots-mase, fig.height=3, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-mase-A-aov-dtsts-plots, fig.cap=paste("Density Plots of the", sts, "statistic by dataset. The density curves for the variants at each level of dataset (not shown) also show non-normality. Shapiro-Wilk tests (not shown) confirmed the visual assessment. These findings were consistent throughout the various stages of the experiment, leading to the choice of non-parametric tests of significance."), fig.height=2}
MyResTheme <- MyLatticeTheme
MyResTheme$plot.line$col <- myPal[7]
MyResTheme$plot.symbol$col <- myPal[7]
MyResTheme$plot.symbol$pch <- 1
dplot <- list()
for (ds in dtsts) {
  dplot[[ds]] <- with(aov_data, 
    densityplot(~aov_data$value[dataset == ds]
                , xlab = ds
                , par.settings = MyResTheme
                , scales = MyLatticeScale)
    )
}

do.call(grid.arrange, args = list(grobs = dplot, nrow = 1))
```

```{r rs-wu-sym-mase-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

The Kruskal-Wallis test finds very strong evidence of a difference in MASE for Scale A between datasets. Figure \@ref(fig:rs-wu-sym-plots-mase) appears to show that the bias in each dataset from smallest to largest was MCAR, MNAR then MAR. This was confirmed with a Tukey's HSD test (not shown). There was no evidence of a difference between the individual method variants for this statistic. 

```{r rs-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-mase-B-aov-dtsts-plots, fig.cap=paste("Density Plots of the", sts, "statistic by dataset. The density curves for the variants at each level of dataset (not shown) also show non-normality. Shapiro-Wilk tests (not shown) confirmed the visual assessment."), fig.height=2}
MyResTheme <- MyLatticeTheme
MyResTheme$plot.line$col <- myPal[7]
MyResTheme$plot.symbol$col <- myPal[7]
MyResTheme$plot.symbol$pch <- 1
dplot <- list()
for (ds in dtsts) {
  dplot[[ds]] <- with(aov_data, 
    densityplot(~aov_data$value[dataset == ds]
                , xlab = ds
                , par.settings = MyResTheme
                , scales = MyLatticeScale)
    )
}

do.call(grid.arrange, args = list(grobs = dplot, nrow = 1))
```

```{r rs-wu-sym-mase-B-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

The Kruskal-Wallis test finds very strong evidence of a difference in MASE for Scale B between datasets. A Tukey's HSD test (not shown) confirmed the visual assessment of Figure \@ref(fig:rs-wu-sym-plots-mase) that the bias is least for MCAR data, with no significant difference between the other two datasets. Again, there is no evidence of a difference between the method variants for the MASE Scale B statistic.

#### Scale means

```{r rs-wu-sym-plots-mean, fig.height=3, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter value.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sym-mean-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

The Kruskal-Wallis test found weak evidence to suggest a significant difference in mean Scale scores for Scale A between datasets but the Tukey's HSD test, which has a more conservative evidence requirement, did not confirm the visual assessment that estimates for MAR data in Scale A were lower than for the other two datasets. Figure \@ref(fig:rs-wu-sym-plots-mean) shows a similar pattern in Scale B with MCAR estimates appearing slightly lower. However, a Kruskal-Wallis test (not shown) did not provide sufficient evidence against the null hypothesis.

The Kruskal-Wallis tests also found no evidence of any difference between the method variants. Nevertheless, there does appear to be a well defined pattern, in both plots of Figure \@ref(fig:rs-wu-sym-plots-mean), indicating that the estimated values for the majority vote methods were slightly lower. This is not statistically significant with an experimental sample size of just 100.

#### Scale Standard Deviations

```{r rs-wu-sym-plots-sd, fig.height=3, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sym-sd-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

There is very strong evidence of a difference in Scale standard deviations scores for Scale A between datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown).

#### Cronbach's alpha

```{r rs-wu-sym-plots-alpha, fig.height=3, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sym-alpha-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

```{r rs-wu-sym-alpha-A-tuk}
aov_res <- aov(value~dataset, data = aov_data)
THSD <- TukeyHSD(aov_res)
print("Tukey's HSD test of difference in means. Adjusted p-values:")
THSD$dataset[, "p adj"]
```

There is very strong evidence to suggest a difference in Cronbach's alpha for Scale A between datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown). A Tukey's HSD test supports the visual assessment that estimates of Cronbach's alpha were significantly different between the three datasets, with the highest estimates given in MNAR data, followed by MCAR and MAR.

#### Split-half Correlation

```{r rs-wu-sym-plots-splith, fig.height=3, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-split-h-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

```{r rs-wu-sym-split-h-tuk}
aov_res <- aov(value~dataset, data = aov_data)
THSD <- TukeyHSD(aov_res)
print("Tukey's HSD test of difference in means. Adjusted p-values:")
THSD$dataset[, "p adj"]
```

The Kruskal-Wallis test finds very strong evidence of a difference in the split-half correlation between datasets. Figure \@ref(fig:rs-wu-sym-plots-splith) appears to show that the bias in each dataset from smallest to largest was MNAR, MAR then MCAR. This was confirmed with a Tukey's HSD test. There was no evidence of a difference between the individual method variants for this statistic. 

#### Ability

```{r rs-wu-sym-ability-attr-aov-dtsts}
sts <- "ability_attr"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-ability-attr-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

```{r rs-wu-sym-ability-case-aov-dtsts}
sts <- "ability_case"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sym-ability-case-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

These results show very strong evidence of a difference in the ability by attribute (data point) and case between datasets. This was confirmed with a Tukey's HSD test (not shown). Tables \@ref(tab:rs-wu-sym-ability-case) and \@ref(tab:rs-wu-sym-ability-attr) show the fully tabulated results for Ability. There was no evidence of a difference between the individual method variants for these statistics.

```{r rs-wu-sym-ability-attr, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_attr"
, c("dataset", "variant", "mean", "st_err")) 
ability_attr <- knitr::kable(
tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by attribute")

ability_attr
```

```{r rs-wu-sym-ability-case, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_case"
, c("dataset", "variant", "mean", "st_err")) 
ability_case <- knitr::kable(
tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by cases")

ability_case
```

```{r rs-ability-vim-plot1, fig.height=2.25, fig.cap='VIM diagnostic plot showing patterns of missingness remaining after imputation for the best rule variant. Showing only the variables that were subject to missingness and imputation.'}
load("sample_results1.RData")
aggr_plot <- aggr(sample_results1$wu_sasym_MCAR_0.3_1000$bestrule[, c(1:3, 7:9)]
                  , col = c(myPalDark[3]
                            , myPal[4])
                  , numbers = TRUE
                  , sortVars = TRUE
                  , labels = names(sample_results1$wu_sasym_MCAR_0.3_1000$bestrule[, c(1:3, 7:9)])
                  , cex.axis = .7
                  , gap = 3
                  , ylab = c("Histogram of missing data","Pattern"))
```

```{r rs-ability-vim-plot2, fig.height=2, fig.cap='VIM diagnostic plot showing patterns of missingness remaining after imputation for the rhs frequency variant. Showing only the variables that were subject to missingness and imputation.'}
aggr_plot <- aggr(sample_results1$wu_sasym_MCAR_0.3_1000$rhsfreq[, c(1:3, 7:9)]
                  , col = c(myPalDark[3]
                            , myPal[4])
                  , numbers = TRUE
                  , sortVars = TRUE
                  , labels = names(sample_results1$wu_sasym_MCAR_0.3_1000$rhsfreq[, c(1:3, 7:9)])
                  , cex.axis = .7
                  , gap = 3
                  , ylab = c("Histogram of missing data","Pattern"))
```

The ability results are also confirmed with a diagnostic plot from the VIM package. This reveals that the remaining pattern of missingness is the same for all the variants. It is not surprising because they all use the same ruleset, which is discovered deterministically by the *apriori* algorithm. See Figures \@ref(fig:rs-ability-vim-plot1) and \@ref(fig:rs-ability-vim-plot2).

### Severely Asymmetric Data

```{r rs_wu_sasym_load_data}
load("rs_wu_sasym_results.RData")

res <- rs_wu_sasym_results

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))

dtsts <- unique(res$results$dataset)
```

#### Mean Absolute Scale Errors

```{r rs-wu-sasym-plots-mase, fig.height=3, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-mase-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)

for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r rs-wu-sasym-mase-A-tuk}
aov_res <- aov(value~dataset, data = aov_data)
THSD <- TukeyHSD(aov_res)
print("Tukey's HSD test of difference in means. Adjusted p-values:")
THSD$dataset[, "p adj"]
```

These results show very strong evidence of a difference in MASE for Scale A between datasets. Figure \@ref(fig:rs-wu-sasym-plots-mase) appears to show that the bias in each dataset from smallest to largest was MCAR, MNAR then MAR. This was confirmed with a Tukey's HSD test. There was no evidence of a difference between the individual method variants for this statistic. Scale B results followed the same pattern (not shown).

#### Scale means

```{r rs-wu-sasym-plots-mean, fig.height=3, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sasym-mean-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

There is very strong evidence of a significant difference in mean Scale scores for Scale A between datasets. A Tukey's HSD test (not shown) confirmed the visual assessment that estimates for MAR data in Scale A were higher than for the other two datasets. There was no evidence of any difference between the mean estimates for Scale B (not shown) and no evidence of any difference between the method variants.

#### Scale Standard Deviations

```{r rs-wu-sasym-plots-sd, fig.height=3, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sasym-sd-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

There is very strong evidence of a difference in Scale standard deviations scores for Scales A datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown).

#### Cronbach's alpha

```{r rs-wu-sasym-plots-alpha, fig.height=3, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r rs-wu-sasym-alpha-A-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

There is very strong evidence to suggest a difference in Cronbach's for Scale A between datasets and no evidence of any difference between the method variants. The same is true for Scale B (results not shown).

#### Split-half Correlation

```{r rs-wu-sasym-plots-splith, fig.height=3, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r rs-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-split-h-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

These results show very strong evidence of a difference in the split-half correlation between datasets. Figure \@ref(fig:rs-wu-sasym-plots-splith) appears to show that the bias in each dataset from smallest to largest was MNAR, MAR then MCAR. This was confirmed with a Tukey's HSD test (not shown). There was no evidence of a difference between the individual method variants for this statistic. 

#### Ability

```{r rs-wu-sasym-ability-attr-aov-dtsts}
sts <- "ability_attr"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-ability-attr-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

```{r rs-wu-sasym-ability-case-aov-dtsts}
sts <- "ability_case"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r rs-wu-sasym-ability-case-aov}
kw_res <- kruskal.test(value~factor(dataset)
                       , data = aov_data)
kw_res$data.name <- paste(sts, "by dataset")
op <- capture.output(kw_res)
op[2] <- sub("\t", "", op[2])
op[4] <- sub("data:  ", "", op[4])
op[4] <- sub("dataset", "dataset, ", op[4])
op[5] <- sub("Kruskal-Wallis ", "", op[5])
op[4] <- paste(op[4:6], collapse = "")
op <- op[c(2, 4)]
print(op)
```

These results show very strong evidence of a difference in the ability by attribute (data point) and case between datasets. This was confirmed with a Tukey's HSD test (not shown). Table \@ref(tab:rs-wu-sasym-ability-case) shows the fully tabulated results for Ability by case. There was no evidence of a difference between the individual method variants for this statistic. 

```{r rs-wu-sasym-ability-case, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "ability_case"
, c("dataset", "variant", "mean", "st_err")) 
ability_case <- knitr::kable(
tab[order(tab$dataset, tab$mean, method = "radix", decreasing = c(FALSE, TRUE)), ]
, digits = 5
, row.names = FALSE
, caption = "Imputation Ability of each method by cases")

ability_case
```

\clearpage

## Stage 2: Default Class Methods

For this stage, a final round of imputation will be applied to any data points for which no useful rule could be found. Two default class methods are compared.

1. Majority Class: After the initial round of AR-based imputations, the distribution is tabulated and the most frequent class is used. In the event of a tie, a random value is taken from the tied values.

1. Class Frequency (stochastic): After the initial round of AR-based imputations, the distribution is tabulated and used as a posterior. A random draw is taken from this distribution for each remaining missing value.

As these methods leave no remaining missing variables, the Ability statistics will not be measured. Also, the difference in performance between the datasets was established in the previous stage and will not be commented on further.

### Symmetric Data

```{r dc_wu_sym_load_data}
load("dc_wu_sym_results.RData")

res <- dc_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r dc-wu-sym-plots-mase, fig.height=1.5, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

```{r dc-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

These results show very strong evidence of a difference in MASE for Scales A and B between the variants. Figure \@ref(fig:dc-wu-sym-plots-mase) shows that variant 1 has the smaller bias. See also Tables \@ref(tab:dc-wu-sym-mase-A) and \@ref(tab:dc-wu-sym-mase-B) 

```{r dc-wu-sym-mase-A, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_A"
         , c("dataset", "variant", "mean", "st_err"))
mase_A <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale A.")

mase_A
```

```{r dc-wu-sym-mase-B, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_B"
         , c("dataset", "variant", "mean", "st_err"))
mase_B <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale B.")

mase_B
```

#### Scale mean

```{r dc-wu-sym-plots-mean, fig.height=1.5, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-mean-A-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

```{r dc-wu-sym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-mean-B-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

There is no evidence of any difference between the two variants for Scale mean of either Scale A or B.

#### Scale Standard Deviations

```{r dc-wu-sym-plots-sd, fig.height=1.5, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-sd-A-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

```{r dc-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

There is strong evidence in the MCAR case, and evidence in MAR and MNAR cases of a difference in Scale standard deviations scores for Scale A, and a similar but not identical pattern in Scale B. A visual assessment of Figure \@ref(fig:dc-wu-sym-plots-sd) shows that variant 2 has the smaller bias. See Tables \@ref(tab:dc-wu-sym-sd-A) and \@ref(tab:dc-wu-sym-sd-B) for the tabulated results.

```{r dc-wu-sym-sd-A, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "sd_A"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))
sd_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("St.Dev of Scale A after imputation. Population value (before) was", round(pop$sd_A, 5)))

sd_A
```

```{r dc-wu-sym-sd-B, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "sd_B"
         , c("dataset", "variant", "mean", "st_err", "rel_bias"))

sd_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
  , digits = 5
  , row.names = FALSE
  , caption = paste("St.Dev of Scale B after imputation. Population value (before) was", round(pop$sd_B, 5)))

sd_B
```

#### Cronbach's alpha

```{r dc-wu-sym-plots-alpha, fig.height=1.5, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-alpha-A-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

```{r dc-wu-sym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r dc-wu-sym-alpha-B-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

There is very strong evidence to suggest a difference in Cronbach's for Scale A and at least evidence at the 0.05 level or less for Scale B between the variants. A visual assessment of Figure \@ref(fig:dc-wu-sym-plots-alpha) shows that variant 1 has the smaller bias. See Tables \@ref(tab:dc-wu-sym-alpha-A) and \@ref(tab:dc-wu-sym-alpha-B) for the tabulated results.

```{r dc-wu-sym-alpha-A, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "alpha_A"
, c("dataset", "variant", "mean", "st_err", "rel_bias"))
alpha_A <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
, digits = 5
, row.names = FALSE
, caption = paste("Cronbach's alpha of Scale A after imputation. Population value (before) was", round(pop$alpha_A, 5)))

alpha_A
```

```{r dc-wu-sym-alpha-B, results='asis'}
tab <- subset(res$qdata
, res$qdata$stats == "alpha_B"
, c("dataset", "variant", "mean", "st_err", "rel_bias"))
alpha_B <- knitr::kable(tab[order(tab$dataset, abs(tab$rel_bias)), ]
, digits = 5
, row.names = FALSE
, caption = paste("Cronbach's alpha of Scale B after imputation. Population value (before) was", round(pop$alpha_B, 5)))

alpha_B
```

#### Split-half Correlation

```{r dc-wu-sym-plots-splith, fig.height=1.5, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sym-split-h-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

There is no evidence of a difference in the split-half correlation between the two variants.

### Severely Asymmetric Data

```{r dc_wu_sasym_load_data}
load("dc_wu_sasym_results.RData")

res <- dc_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r dc-wu-sasym-plots-mase, fig.height=1.5, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r dc-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sasym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

```{r dc-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r dc-wu-sasym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- wilcox.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[3] <- sub("\t", "Wilcoxon rank sum test for ", op[3])
  op[5] <- paste(op[5], op[6], collapse = "")
  op <- op[c(3, 5)]
  print(op)
}
```

There was no evidence of a difference in MASE for Scales A between the two variants. For Scale B, there was very strong evidence exept in the MAR case, where there was none. Figure \@ref(fig:dc-wu-sasym-plots-mase) shows that variant 1 has the smaller bias in the case of Scale B. See also Table  \@ref(tab:dc-wu-sasym-mase-B).

```{r dc-wu-sasym-mase-B, results='asis'}
tab <- subset(res$qdata
         , res$qdata$stats == "mase_B"
         , c("dataset", "variant", "mean", "st_err"))
mase_B <- knitr::kable(tab[order(tab$dataset, tab$mean), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Mean Absolute Scale Error for Scale B.")

mase_B
```

#### Scale means

```{r dc-wu-sasym-plots-mean, fig.height=1.5, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Mann-Whitney-Wilcoxon test (not shown) found no evidence of any difference between the two variants for Scale mean of either Scale A or B.

#### Scale Standard Deviations

```{r dc-wu-sasym-plots-sd, fig.height=1.5, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Mann-Whitney-Wilcoxon test (not shown) found no evidence of any difference between the two variants for Scale standard deviations for either Scale A or B.

#### Cronbach's alpha

```{r dc-wu-sasym-plots-alpha, fig.height=1.5, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Mann-Whitney-Wilcoxon test (not shown) found no evidence of any difference between the two variants for Scale standard deviations for either Scale A or B.

#### Split-half Correlation

```{r dc-wu-sasym-plots-splith, fig.height=1.5, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

There is no evidence of a difference in the split-half correlation between the two variants.

## Stage 3: Interestingness Measures

For this stage, *Confidence*, La Place Prediction Accuracy, Chi Square and Weighted Chi Square are compared to determine whether any has a positive effect on performance.

### Symmetric Data

```{r im_wu_sym_load_data}
load("im_wu_sym_results.RData")

res <- im_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r im-wu-sym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

The Kruskal-Wallis test (not shown) did not find any evidence of significant differences between the variants.

#### Scale means

```{r im-wu-sym-plots-mean, fig.height=2, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Kruskal-Wallis test (not shown) found no evidence of any difference between the variants for Scale mean of either Scale A or B.

#### Scale Standard Deviations

```{r im-wu-sym-plots-sd, fig.height=2, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r im-wu-sym-sd-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2:3]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

A Kruskal-Wallis test (not shown) found no evidence of a difference in means of the Scale standard deviations for Scale A. However, for Scale B, there is weak evidence of a difference in Scale standard deviations for dataset MAR and evidence for dataset MNAR. A visual assessment of Figure \@ref(fig:im-wu-sym-plots-sd) suggests that Chi squared and weighted Chi squared are slightly ahead of the other two but a Tukey's HSD test is not conclusive.

#### Cronbach's alpha

```{r im-wu-sym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

The Kruskal-Wallis (not shown) test finds no evidence of difference in Cronbach's alpha for eaither Scales A and B between the variants.

#### Split-half Correlation

```{r im-wu-sym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

The Kruskal-Wallis (not shown) test finds no evidence of difference in Cronbach's alpha for eaither Scales A and B between the variants.

\clearpage

### Severely Asymmetric Data

```{r im_wu_sasym_load_data}
load("im_wu_sasym_results.RData")

res <- im_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r im-wu-sasym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r im-wu-sasym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r im-wu-sasym-mase-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r im-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r im-wu-sasym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r im-wu-sasym-mase-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2:3]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for Scale A between the variants. Also, for Scale B, there was weak evidence in the MAR and MNAR cases. Figure \@ref(fig:im-wu-sasym-plots-mase) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this, at least in the Scale A case.

#### Scale means

```{r im-wu-sasym-plots-mean, fig.height=2, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

A Kruskal-Wallis test (not shown) found no evidence of any difference among the variants between the Scale mean of either Scale A or B.

#### Scale Standard Deviations

```{r im-wu-sasym-plots-sd, fig.height=2, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-sd-A-aov, eval=TRUE}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  print(kw_res)
}
```

```{r im-wu-sasym-sd-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r im-wu-sasym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r im-wu-sasym-sd-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in Scale standard deviations for Scale A between the variants. Also, for Scale B, there was very strong evidence in the MAR case. Figure \@ref(fig:im-wu-sasym-plots-sd) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this.

#### Cronbach's alpha

```{r im-wu-sasym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-alpha-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r im-wu-sasym-alpha-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r im-wu-sasym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r im-wu-sasym-alpha-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

There was very strong evidence of a difference in Cronbach's alpha for Scale A between the variants. Also, for Scale B, there was weak evidence in the MAR case. Figure \@ref(fig:im-wu-sasym-plots-sd) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test confirms this for Scale A.

#### Split-half Correlation

```{r im-wu-sasym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r im-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r im-wu-sasym-split-h-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

There was evidence of a difference in split-half correlation between the variants in the MAR case and weak evidence in the MNAR case. Figure \@ref(fig:im-wu-sasym-plots-sd) appears to show Chi squared and weighted Chi squared variants ahead of the other two. The Tukey's HSD test (not shown), with it's more conservative evidence requirements, fails to confirm the visual assessment.

\clearpage

## Stage 4: Variants

This stage compares the basic single, all at once imputation with variants based on the sequential-iterative process (modeled on MICE), propensity scoring and feature engineering with precalculated scale means.  The following coding is used:
  
1. bestdc1chi: All other variants are extended from this base which uses best rule by Chi square precedence and defaults to majority class is if no matching rule is found. This combination was chosen based on the optimum results of the previous stages.
1. bestdc1chico: The dataset is extended by the addition of a co-variate for each item of the multi-item scale which is calculated as the mathematically rounded mean of the scale excluding that individual item. Minimum support is adjusted upwards to account for the larger number of variables but this still adds considerable time and complexity to the process.
1. ibestdc1chi: As above but the imputation is performed sequentially and iteratively one variable at a time on the basic dataset. A new set of CARs is generated for every step.
1. ibestdc1chico: As above, the sequential-iterative variant for the extended dataset.
1. ibestdc1chip: Between each sequential step, a logistic regression is performed of the next variable in the sequence onto all the other variables and the predicted probability, or propensity for missingness is used to rank and split the dataset into two evenly sized subsets. The imputation steps are carried out separately on each split.
1. ibestdc1chipco: As above, for the extended dataset.

### Symmetric Data

```{r vr_wu_sym_load_data}
load("vr1_wu_sym_results.RData")

res <- vr_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r vr-wu-sym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-mase-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-mase-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants. A visual assessment indicates that ibestdc1chico is well ahead in both cases but no separation between several others in joint second place. This is confirmed by Tukey's HSD test. See Figure \@ref(fig:vr-wu-sym-plots-mase).

#### Scale means

```{r vr-wu-sym-plots-mean, fig.height=2, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-mean-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-mean-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[1:2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-mean-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

The Kruskal-Wallis test found evidence of a difference in Scale means but only for the MCAR and MAR cases in scale A. The Tukey's HSD test does not confirm this because of the more conservative evidence requirements. There is no evidence of any difference for Scale B Scale means. See Figure \@ref(fig:vr-wu-sym-plots-mean).

#### Scale Standard Deviations

```{r vr-wu-sym-plots-sd, fig.height=2, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-sd-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-sd-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-sd-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in Scale standard deviations for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sym-plots-sd) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chip and ibestdc1chipco are joint leaders.

#### Cronbach's alpha

```{r vr-wu-sym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-alpha-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-alpha-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sym-alpha-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-alpha-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sym-plots-mean) shows a nuanced result where ibestdc1chip, ibestchipco and ibestchico take the lead for different combinations of Scale and dataset.

#### Split-half Correlation

```{r vr-wu-sym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sym-split-h-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sym-split-h-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found strong (MCAR) to very strong evidence (MAR, MNAR) of a difference in split-half correlation between the variants which is confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sym-plots-mean) shows a nuanced result, and for the first time one of the variants ibestdc1chip actually over-estimates the population parameter. To this point, the parameters have always been biased downwards.

### Severely Asymmetric Data

```{r vr_wu_sasym_load_data}
load("vr1_wu_sasym_results.RData")

res <- vr_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r vr-wu-sasym-plots-mase, fig.height=2, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sasym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-mase-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sasym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-mase-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2:3]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants which are confirmed by Tukey's HSD test. However, the variants with the smallest bias are different in each case, as can be seen in Figure \@ref(fig:vr-wu-sasym-plots-mase). For Scale A, ibestdc1chip is ahead of the others for all datasets but the same variant has not performed so well on Scale B.

#### Scale means

```{r vr-wu-sasym-plots-mean, fig.height=2, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-mean-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-mean-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

There was very strong evidence of a difference in Scale means for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-mean) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chipco does even better.

#### Scale Standard Deviations

```{r vr-wu-sasym-plots-sd, fig.height=2, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-sd-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-sd-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sasym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-sd-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in Scale standard deviations for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-sd) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chipco does even better.

#### Cronbach's alpha

```{r vr-wu-sasym-plots-alpha, fig.height=2, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-alpha-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-alpha-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r vr-wu-sasym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r vr-wu-sasym-alpha-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

There was very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-mean) shows ibestdc1chip ahead of the others for all datasets for Scale A. For Scale B ibestdc1chipco does even better while ibestdc1chico comes second for MAR data. Important to note that the latter did worst of all for Scale A mean and standard deviation.

#### Split-half Correlation

```{r vr-wu-sasym-plots-splith, fig.height=2, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r vr-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r vr-wu-sasym-split-h-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r vr-wu-sasym-split-h-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in split-half correlation between the variants which is confirmed by Tukey's HSD test. Figure \@ref(fig:vr-wu-sasym-plots-mean) shows ibestdc1chip ahead of the others for all datasets.

## Stage 5: Benchmarks

The best performing variant of the novel AR-based imputation (ibestdc1chip) method is run as a multiple imputation, i.e. it is run to convergence m \footnote{m = 5 for the MI techniques in this section.} times. The final estimates are made using Rubin's rules to combine the m imputed datasets. The results are compared with the following benchmark techniques:
  
1. PM: Person mean imputation. See \@ref(eq:personmean) and \@ref(eq:pmimp).
1. CIM: Corrected item mean imputation. See \@ref(eq:personmean) to \@ref(eq:personitemmean) and \@ref(eq:cimimp).
1. TW: Two-way imputation. See \@ref(eq:personmean) to \@ref(eq:totalmean) and \@ref(eq:twimp).
1. ICS: Item correlation substitution. See \@ref(eq:icsimp).
1. amelia: Multiple Imputation by expectation maximization with bootstrapping, as implemented in the Amelia II package, @R-Amelia. See \secref{sec:singimp} for further details.
1. mice: Multiple Imputation with Chained Equations, as implemented in the mice package, @R-mice. See \secref{sec:singimp} for further details.

The relative bias of each statistic is calculated as an additional performance measure. This serves to shed more light on any non-significant Kruskal-Wallis test results. See \@ref(eq:relbias).

### Symmetric Data

```{r bm_wu_sym_load_data}
load("bm1_wu_sym_results.RData")

res <- bm_wu_sym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r bm-wu-sym-plots-mase, fig.height=2.25, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-mase-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-mase-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants. A visual assessment indicates that ibestdc1chico has outperformed the benchmark MI techniques. However, the single imputation techniques perform somewhat better here with no clear leader. This is confirmed by Tukey's HSD test. See Figure \@ref(fig:bm-wu-sym-plots-mase).

#### Scale means

```{r bm-wu-sym-plots-mean, fig.height=2.25, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-mean-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-mean-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-mean-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-mean-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found strong evidence of a difference in Scale means for both Scales A and B but only for the MAR case. The Tukey's HSD test found that the difference was only detectable between PM and the other single imputation techniques and does not impact on this research. See Figure \@ref(fig:bm-wu-sym-plots-mean).

Table \@ref(tab:bm-wu-sym-mean-A-relb) shows the relative bias introduced by each imputation method on Scale A. ibestdc1chip is at the bottom of the table and sometimes more than double the better performing techniques. Nevertheless, in each case, the statistic is well within the acceptable limit of < 0.05 to be considered a good performing imputation method. Contrastingly, Table \@ref(tab:bm-wu-sym-mean-B-relb) shows ibestdc1chip does very well for Scale B with MAR and MNAR data.

```{r bm-wu-sym-mean-A-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "mean_A"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_meanA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A mean for each imputation method.")

relb_meanA
```

```{r bm-wu-sym-mean-B-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "mean_B"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_meanB <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale B mean for each imputation method.")

relb_meanB
```

#### Scale Standard Deviations

```{r bm-wu-sym-plots-sd, fig.height=2.25, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-sd-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-sd-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-sd-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in Scale standard deviations for both Scales A and B between the variants. Tukey's HSD test confirm the visual assessment that ibestdc1chip underperformed in all three datasets for Scale B but the results for Scale A were more nuanced. Nevertheless, good performance in the MNAR case is perhaps offset by the lack of consistency and it would be fair to say that the novel method is the worst performer against this measure. See Figure \@ref(fig:bm-wu-sym-plots-sd).

Tables \@ref(tab:bm-wu-sym-sd-A-relb) and \@ref(tab:bm-wu-sym-sd-B-relb) reflect the poorer performance of ibestdc1chip in preserving the Scale standard deviations. On MAR data, the relative bias has exceeded the acceptable limit of < 0.05 to be considered a good performing imputation method.

```{r bm-wu-sym-sd-A-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "sd_A"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_sdA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A standard deviation for each imputation method.")

relb_sdA
```

```{r bm-wu-sym-sd-B-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "sd_B"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_sdB <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale B standard deviation for each imputation method.")

relb_sdB
```

#### Cronbach's alpha

```{r bm-wu-sym-plots-alpha, fig.height=2.25, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-alpha-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-alpha-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sym-alpha-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-alpha-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. The results are very nuanced and worth considering further. All the single imputation methods tended to bias the alpha statistic upwards by around two percentage points, while ibestdc1chip and amelia tended towards a downward bias of a smaller magnitude. ibestdc1chip beat amelia in the MCAR and MNAR cases. Overall mice was the best performer for this measure, returning an estimate with no detectable difference from the population parameter. See Figure \@ref(fig:bm-wu-sym-plots-mean).

Tables \@ref(tab:bm-wu-sym-alpha-A-relb) and \@ref(tab:bm-wu-sym-alpha-B-relb) show that the relative bias is within the acceptable limit of < 0.05 to be considered a good performing imputation method.

```{r bm-wu-sym-alpha-A-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "alpha_A"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_alphaA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A standard deviation for each imputation method.")

relb_alphaA
```

```{r bm-wu-sym-alpha-B-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "alpha_B"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_alphaB <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale B standard deviation for each imputation method.")

relb_alphaB
```

#### Split-half Correlation

```{r bm-wu-sym-plots-splith, fig.height=2.25, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sym-split-h-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sym-split-h-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found very strong evidence of a difference in the split-half correlation between the variants which are confirmed by Tukey's HSD test. The upwards bias in the estimates from the single imputation techniques on this statistic is rather startling. It appears to be so great that the two Scales would be considered to be associated in any test of reliability. This has very serious consequences for subsequent data analysis. ibestdc1chip compares very favourably with mice and amelia. All three very closely preserve the population parameter. See Figure \@ref(fig:bm-wu-sym-plots-splith).

Table \@ref(tab:bm-wu-sym-splith-relb) serves to illustrate the very poor performance of the single imputation techniques with Split-half correlation relative bias exceeding a value of 1.0, compared to the acceptable value of 0.05. Both mice and ibestdc1chip slightly exceeded the acceptable limit in one or more datasets and it turns out the amelia is the best performing method for this specific statistic. This was not immediately obvious from the visual assessment, due to the overwhelming scale of the single imputation methods.

```{r bm-wu-sym-splith-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "splith_mix"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_splith <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of split-half correlation for each imputation method.")

relb_splith
```

### Severely Asymmetric Data

```{r bm_wu_sasym_load_data}
load("bm1_wu_sasym_results.RData")

res <- bm_wu_sasym_results

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sasym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
```

#### Mean Absolute Scale Errors

```{r bm-wu-sasym-plots-mase, fig.height=2.25, fig.cap='Mean Absolute Scale Errors after imputation.'}
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-mase-A-aov-dtsts}
sts <- "mase_A"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sasym-mase-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-mase-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-mase-B-aov-dtsts}
sts <- "mase_B"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sasym-mase-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-mase-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in MASE for both Scales A and B between the variants. A visual assessment indicates that ibestdc1chico outperformed the benchmark MI techniques for Scale B but was the worst performer for Scale A. As with the symmetric data, the single imputation techniques perform somewhat better here with no clear leader, although PM was the worst of these. This is confirmed by Tukey's HSD test. See Figure \@ref(fig:bm-wu-sasym-plots-mase).

#### Scale means

```{r bm-wu-sasym-plots-mean, fig.height=2.25, fig.cap='Scale means after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
            )
) +
  labs(y = "variant") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-mean-A-aov-dtsts}
sts <- "mean_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-mean-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-mean-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-mean-B-aov-dtsts}
sts <- "mean_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-mean-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-mean-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts[2]) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found strong evidence of a difference in Scale means for both Scales A and B. This is confirmed by the Tukey's HSD test. The visual assessment shows the AR-based imputation performing worst of all in both scales. See Figure \@ref(fig:bm-wu-sasym-plots-mean).

Table \@ref(tab:bm-wu-sasym-mean-A-relb) shows the relative bias for Scale A with ibestdc1chip is at the bottom of the table, exceeding the acceptable limit of < 0.05. Contrastingly, Table \@ref(tab:bm-wu-sasym-mean-B-relb) shows ibestdc1chip is well within boundary even though it doesn't perform as well as the other methods.

```{r bm-wu-sasym-mean-A-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "mean_A"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_meanA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A mean for each imputation method.")

relb_meanA
```

```{r bm-wu-sasym-mean-B-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "mean_B"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_meanB <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale B mean for each imputation method.")

relb_meanB
```

#### Scale Standard Deviations

```{r bm-wu-sasym-plots-sd, fig.height=2.25, fig.cap='Scale standard deviations after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-sd-A-aov-dtsts}
sts <- "sd_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-sd-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-sd-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-sd-B-aov-dtsts}
sts <- "sd_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-sd-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-sd-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

There was very strong evidence of a difference in Scale standard deviations for both Scales A and B between the variants. Tukey's HSD test confirm the visual assessment that ibestdc1chip underperformed in all three datasets for Scale B but the results for Scale A were more nuanced. Nevertheless, good performance in the MNAR case is perhaps offset by the lack of consistency and it would be fair to say that the novel method is the worst performer against this measure. See Figure \@ref(fig:bm-wu-sasym-plots-sd).

Table \@ref(tab:bm-wu-sasym-sd-A-relb) shows ibestdc1chip performing consistently well on Scale A standard deviation, while the single imputation methods have been challenged by the severely asymmetric data. On the other hand, Table \@ref(tab:bm-wu-sasym-sd-B-relb) shows poorer performance on Scale B for ibestdc1chip as relative exceeded the acceptable limit of < 0.05.

```{r bm-wu-sasym-sd-A-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "sd_A"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_sdA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A standard deviation for each imputation method.")

relb_sdA
```

```{r bm-wu-sasym-sd-B-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "sd_B"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_sdB <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale B standard deviation for each imputation method.")

relb_sdB
```

#### Cronbach's alpha

```{r bm-wu-sasym-plots-alpha, fig.height=2.25, fig.cap='Cronbach\'s alpha after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-alpha-A-aov-dtsts}
sts <- "alpha_A"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-alpha-A-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-alpha-A-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

```{r bm-wu-sasym-alpha-B-aov-dtsts}
sts <- "alpha_B"

aov_data <- with(res$results,
                 res$results[stats == sts, ])
```

```{r bm-wu-sasym-alpha-B-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-alpha-B-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found very strong evidence of a difference in Cronbach's alpha for both Scales A and B between the variants which are confirmed by Tukey's HSD test. The results are very nuanced and worth considering further. All the single imputation methods tended to bias the alpha statistic upwards by around two percentage points, while ibestdc1chip and amelia tended towards a downward bias of a smaller magnitude. ibestdc1chip beat amelia in the MCAR and MNAR cases. Overall mice was the best performer for this measure, returning an estimate with no detectable difference from the population parameter.  See Figure \@ref(fig:bm-wu-sasym-plots-mean).

Tables \@ref(tab:bm-wu-sasym-alpha-A-relb) and \@ref(tab:bm-wu-sasym-alpha-B-relb) show that the relative bias of introduced by ibestdc1chip is within the acceptable limit of < 0.05, with the exception of Scale B on MAR data where it is slightly over.

```{r bm-wu-sasym-alpha-A-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "alpha_A"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_alphaA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A standard deviation for each imputation method.")

relb_alphaA
```

```{r bm-wu-sasym-alpha-B-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "alpha_B"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_alphaB <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale B standard deviation for each imputation method.")

relb_alphaB
```

#### Split-half Correlation

```{r bm-wu-sasym-plots-splith, fig.height=2.25, fig.width=4.5, fig.cap='Split-half correlation after imputation with 95% confidence interval on 99 df. Dotted line shows population parameter.'}
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
            )
) +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
```

```{r bm-wu-sasym-splith-aov-dtsts}
sts <- "splith_mix"

aov_data <- with(res$results,
     res$results[stats == sts, ])
```

```{r bm-wu-sasym-split-h-aov}
for (ds in dtsts) {
  kw_res <- kruskal.test(value~factor(variant)
                       , subset = aov_data$dataset == ds
                       , data = aov_data)
  kw_res$method <- paste(kw_res$method, "for", ds)
  kw_res$data.name <- paste(sts, "by variant")
  op <- capture.output(kw_res)
  op[2] <- sub("\t", "", op[2])
  op[4] <- sub("data:  ", "", op[4])
  op[4] <- sub("variant", "variant, ", op[4])
  op[5] <- sub("Kruskal-Wallis ", "", op[5])
  op[4] <- paste(op[4:6], collapse = "")
  op <- op[c(2, 4)]
  print(op)
}
```

```{r bm-wu-sasym-split-h-tuk}
print("Tukey's HSD test of difference in means")
for (ds in dtsts) {
  aov_res <- aov(value~variant
                 , data = subset(aov_data
                                 , dataset == ds))
  THSD <- TukeyHSD(aov_res)
  
  
  print(paste("Adjusted p-values for dataset", ds))
  print(THSD$variant[, "p adj"])
}
```

The Kruskal-Wallis test found very strong evidence of a difference split-half correlation between the variants which is confirmed by Tukey's HSD test. The upwards bias in the estimates from the single imputation techniques on this statistic is rather startling. It appears to be so great that the two Scales would be considered to be associated in any test of reliability. This is very serious consequences for subsequent data analysis. ibestdc1chip compares very favourably with mice and amelia. All three very closely preserve the population parameter. See Figure \@ref(fig:bm-wu-sasym-plots-splith).

Table \@ref(tab:bm-wu-sasym-splith-relb) serves to illustrate the very poor performance of the single imputation techniques with Split-half correlation relative bias exceeding a value of 1.0, compared to the acceptable value of 0.05. ibestdc1chip also exceeded the acceptable limit in MCAR and MNAR data but performed best on MAR data. The reasons for such inconsistency are a matter for further research.

```{r bm-wu-sasym-splith-relb}
tab <- subset(res$qdata
              , res$qdata$stats == "splith_mix"
              , c("dataset", "variant", "mean", "rel_bias")) 
relb_splith <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of split-half correlation for each imputation method.")

relb_splith
```