<<prologue, include=FALSE>>=
knitr::opts_chunk$set(warning = FALSE
                      , message = FALSE
                      , echo = FALSE
                      )
knitr::opts_template$set(
  fig.tile = list(fig.height = 3
                  , fig.width = 3
                  , fig.align='center')
  )
knitr::opts_knit$set(self.contained=FALSE)
source("C:\\Dev\\Study\\R\\R_Themes\\MarketingTheme.R")
MyTempTheme <- MyLatticeTheme
MyTempTheme$superpose.symbol$col <- myPal
MyTempTheme$add.line$col <- myPalDark[3]

load("wu_stats_pop.RData")
@

\documentclass[format=sigconf, natbib=false]{acmart}

\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage[backend=bibtex, maxcitenames=2, bibstyle=numeric, citestyle=numeric, sorting=none]{biblatex}
\addbibresource{likertimputebiblio.bib}
\addbibresource{packages.bib}

\begin{document}

\title{I-ISARP: Imputation by Iterative-Sequential Association Rules with Propensity}

\begin{abstract}
A novel imputation method, I-ISARP, is presented based on association rules mining (ARM). From a thorough review of the literature, it is believed that this is the first association rules (AR) based imputation method specifically intended for use with ordinal data and Likert scales. ARM was selected as the core for this method because it is a distribution free process that exploits inter-item relationships through probabilistic measures such as \textit{Support} and \textit{Confidence}. By implementing an iterative-sequential approach, similar to Multiple Imputation with chained equations (MICE), but using AR instead of an underlying MVN model, I-ISARP has the potential to impute missing data in a range of niche applications such as highly skewed or multi-modal Likert scales. An experimental study was undertaken to compare I-ISARP to various benchmark techniques using synthetic data that simulates Likert scales, such as may be found in many surveys and questionnaires. I-ISARP was found to perform as well as the benchmarks and offers many user-configurable tuning parameters for further refinement based on specific user requirements.
\end{abstract}

\maketitle

\section{Introduction}

Even in the era of unstructured "Big Data" and the demise of paper and telephone based questionnaires \parencite{groves2011three}, structured surveys remain an essential tool in commercial enterprise and other areas because of their easy conversion to online use. \parencite{evans2005value} shows that online surveys were already a rapidly growing, multi-million dollar industry by the early 2000's and \parencite{schultz2015psychology} states that most companies now use web-based surveys. Yet, the practicalities of running surveys means non-response and missing data is the rule, not the exception \parencite{plumpton2016multiple, bono2007missing, kamakura2000factor}. If handled incorrectly, missing data can cause loss of statistical power and biased parameter estimates, which increases the likelihood of drawing incorrect inferences and erroneous conclusions. These are non-trivial problems, which at best tarnish reputations, breach ethical codes and incur expense of repeated studies, \parencite{button2013power}. At worst, flawed results can affect social and economic policy making, business strategies and clinical results, \parencite{barrett2015data}.\par
Imputation is a collection of methods for recovering from missing data that substitute missing values with estimated values. Multiple imputation (MI) is currently most important of these. In MI, a stochastic process delivers multiple versions of the imputed data by drawing values from a multi-variate normal (MVN) model of the observed data. However, the reliance on an assumption of underlying MVN distribution means that workarounds and additional configuration is required to use MI on survey data that are mostly discrete data types, namely binary, nominal, ordinal and Likert, \parencite{R-Amelia, R-mi, johnson2009working, christensen2010ordinal}. A review of the literature finds scarce examples of imputation techniques naturally suited to these data types, especially ordinal and Likert scales and various authors indicate that the development of such methods remains an open research question \parencite{finch2010imputation, leite2010performance}.\par
ARM, which is best suited to applications on categorical data is inherently a descriptive, knowledge discovery tool. It has been successfully adapted for classification. However, during a detailed review of the literature it was very difficult to find examples of ARM in imputation, and none that specifically address the challenge of ordinal data. This research proposes a new algorithm I-ISARP to bridge this gap by replacing the MVN assumption of MI with ARM which is essentially non-parametric and distribution free, while being a perfect fit for finding relationships between variables, such as the inter-item correlation that is an integral part of Likert scale reliability analysis.\par
The remainder of this paper continues as follows. Section 2 covers essential background material, Section 3 discusses related work. In section 4 the IISARP algorithm is presented in two parts: the inner AR-based impuation and the outer iterative-sequential process with propensity. Section 5 describes the experimental study in detail and Section 6 presents the results. A discussion follows in Section 7 and Section 8 concludes with suggestions for further work.

\section{Preliminaries}

The following is a brief treatment of key background topics, comprising Likert scales, missing data and ARM.

\subsection{Ordinal Data and Likert Scales}
This research is primarily concerned with assessed ordered categorial variables (AOCV), whereby a judgement is given on the grade, level or rank some of information which itself is not an observed variable. These differ from grouped continuous variables (GCV) where an underlying, normally distributed, continuous variable such age, height or weight is discretized into buckets or categories. AOCV generally take the form $k \in \{0,\ \dots,\ K\}$ or $k \in \{1,\ \dots,\ K\}$ or sometimes a symmetric form $k \in \{-K,\ \dots,\ 0,\ \dots,\ K\}$ and all are interpreted as a monotonic, ranking representation $Least \succ Less \succ More \succ Most$. They can be used individually but items related to a specific concept are often combined into multiple-item response variables (MIRVs). One well-known format of MIRV is the Likert scale, whereby each individual item is an integer series anchored to phrases of sentiment or attitude (e.g. 1 = strongly disagree, 5 = strongly agree). The collection of item responses measure facets of some latent (unobserved) concept or factor. The respondents' positions on the latent factor can then be estimated by summing or averaging the individual item scores \parencite{carpita2011imputation}. Likert scales are ubiquitous in behavioural science, marketing, usability, customer feedback, psychological and clinical research because they effectively convert qualitative data into quantitative data and simplify the survey method \parencite{schultz2015psychology, christensen2010ordinal}. 

\subsection{Missing Data}
A tabular dataset can have the presence or absence of each data point represented as a missing indicator matrix of equal dimension. The following definitions are adapted from \parencite{carpita2011imputation} to describe such a dataset made up of Likert scales; Let $X$ be a data matrix and $M$ be the corresponding missing indicator matrix. Both $X$ and $M$ are $n \times p$ matrices. Let $K$ be the number of ordinal categories in each item and $x_{ij}$ be respondent $i$'s answer to item $j$. Then the value of $x_{ij}$ is: 

\begin{equation}
  \begin{gathered}
  x_{ij} =
  \begin{cases} 
  k \in \{1,\ 2, \ \dots, \ K\ \},\ \text{if}\ m_{ij} = 0 \\
  \text{missing}, \text{otherwise}
  \end{cases},\\
  m_{ij} \in \{0,\ 1\},\\
  i \in \{1,\ 2, \ \dots,\ n\ \},\\
  j \in \{1,\ 2, \ \dots, \ p\ \}
  \end{gathered}
\end{equation}

The respondent $i$ has no missing data when $m_{i+} = \sum^p_{j=1} m_{ij} = 0$ and data is missing when $m_{i+} > 0$. The items for respondent $i$ where data are not missing are counted as $p_{i+} = p - m_{i+}$ and their indices are collected in the set $A(i)$. The indices of all the missing items for respondent $i$ is $A'(i)$. Similarly, the item $j$ has no missing data when $m_{+j} = \sum^n_{i=1} m_{ij} = 0$ and data is missing when $m_{+j} > 0$. There are $n_{+j} = n - m_{+j}$ respondents with observed data and the indices of these are collected for item $j$ in set $B(j)$. The indices of all the missing respondents for item $j$ is $B'(j)$.\newline

Donald B. Rubin is widely cited for seminal works, including \parencite{rubin1987multiple}, on modeling, recovering (imputing) and inference using missing data. This body of work formalizes the relationship between the missing values, the incomplete variable and the other variables. The data matrix $X$ is comprised of $X^{obs}$, the observed portion, and $X^{mis}$, the missing portion of the data. 

\begin{equation}
  \forall x_{ij} \in X^{obs},\ m_{ij} = 0\ \land \forall x_{ij} \in X^{mis},\ m_{ij} = 1
\end{equation}

Patterns arising from these relationships are categorized as:

\begin{itemize}
\item Missing completely at random (MCAR) if the distribution of missing data is unrelated to the value of any variable in the dataset. It is suggested in \parencite{gelman2006data} that the probability of non-response is the same for all points of the missing indicator matrix. The missing/non-missing state of individual data points cannot be predicted from any information whatever, whether observed or unobserved:

\begin{equation}
  P(M \mid X) = P(M)
\end{equation}

\item Missing at random (MAR) is more likely that MCAR according to \parencite{raaijmakers1999effectiveness} cited in \parencite{jonsson2006benchmarking}. It applies if the distribution of missing data is correlated to $X^{obs}$ but not the variable itself according to \parencite{gelman2006data}. The missing indicator matrix can be modelled as a logistic regression. The resulting probabilities give the propensity score for the point $x_{ij}$ to be missing:

\begin{equation}
  P(M \mid X) = P(M \mid X^{obs})
\end{equation}

\item Missing not at random (MNAR) if the distribution of missing data is related to data that is unobserved and, according to \parencite{gelman2006data}, can be further subdivided as:
  \begin{itemize}
  \item Missingness depending unobserved predictors. For example, people in a particular education bracket respond less frequently to questions about income and there were no questions identifying educational attainment.
  \begin{equation}
  P(M \mid X) = P(M \mid Z),\ Z \cap X = \varnothing,\ Z\  \text{are unobserved}
  \end{equation}

  \item Missing data is related to the value of the partially missing variable, such that answers given by complete respondents differ from answers that would have been given by non-respondents. For example, respondents from a lower income bracket are reluctant to respond to questions about earnings:
  \begin{equation}
P(M \mid X) = P(M \mid X^{mis})
  \end{equation}
  \end{itemize}
\end{itemize}

MNAR is the most challenging situation to recover and of most concern to researchers. \parencite{leite2010performance}, \parencite{tsikriktsis2005review} and \parencite{jonsson2004evaluation} all claim that it is very difficult or impossible to recover a dataset that is MNAR. \parencite{gelman2006data} suggests that the problem can only be mitigated by adding more predictors to make the MAR assumption tenable.

\subsection{ARM in Brief}
The motivation for ARM's popularity is its commercial application in the large retail enterprise sector. It is most frequently used for identifying purchasing patterns in customer data, \parencite{garcia2004mining}. Many of the fundamental concepts of ARM were formalised in \parencite{agrawal1993mining} and its follow up, \parencite{agrawal1994fast}, which are considered to be the seminal works on the topic and generated a boom in popularity of the method. The following definitions are adapted from these and \parencite{tan2005chapter6} (pp.329-330):

Let $I = \{i_1,\ i_2,\ \dots,\ i_k\}$ be the set of all available items. Let $T = \{t_1,\ t_2,\ \dots,\ t_N\}$ be a set of $N$ transactions where each transaction $t_j \subseteq I$. A transaction $t_j$ is said to contain an itemset $X$ (a set of some items in $I$) if $X \subseteq t_j$. Association rules (AR) can be inferred from the frequently occurring itemsets. AR take the pattern $X \implies Y$ (read as $X\ \text{implies}\ Y$) where $X \subseteq t_j$ is the \textit{antecedent} of a rule and $Y \subseteq t_j$ is the \textit{consequent} and $X \cap Y = \varnothing$. Although not strictly part of the definition of AR given in \parencite{agrawal1994fast}, this research applies a restriction that the cardinality $|Y| = 1$ because AR are to be used to estimate a value for one target variable at a time in a manner similar to classification.\par
There has been a good deal of research into prediction/classification techniques based on ARM. Classification Based on Associations (CBA) is perhaps the oldest of these methods, described in various sources e.g. \parencite{R-arulesCBA, yin2003cpar, freitas2000understanding}. It is an intuitive approach with performance comparable to other classification algorithms. Nevertheless, it is not among the techniques typically taught in data science classes or described in the literature. CBA involves finding a subset of rules, which have the characteristic of having the target variable as the only element in the consequent, or right-hand side, of the rule. \parencite{ma1998integrating} calls these types of AR ``class association rules" (CARs). To predict on new data, the rules satisfied in the antecedent by the predictor variables are retrieved and the one with the highest \textit{Confidence} predicts the class label from its consequent. \parencite{li2001cmar} discusses the major disadvantage of AR for classification, which is the trade off between maintaining a high enough support to create a tenable model, while searching for rules that cover even the rarest cases. This is of concern to this research because of the requirement to find rules that cover any foreseeble set of predictor values. Without a matching rule, the model has to fall back on the default class, which can be inapproprate for a rare set of predictor values. \parencite{liu2001classification} suggests flexibly assigning a lower minimum \textit{Support} threshold to minority classes to overcome this problem.

\section{Related Work}
An example of a similar benchmarking experiment, using a non-parametric, Hot-decking (similarity-based) imputation method for Likert scales is \parencite{jonsson2004evaluation} and \parencite{jonsson2006benchmarking} which uses K-Nearest Neighbours based imputation. \parencite{carpita2011imputation} extends the another well-known, non-parametric, stochastic technique, the Approximate Bayesian Bootstrap (ABB) with a propensity and a nearest neighbour selection. The experimental design in this paper is of particular relevance because it avoids design bias by including benchmark techniques that are specifically useful for Likert scales, whereas many other authors benchmark against techniques that are previously known to be less effective. \parencite{wu2007novel} and \parencite{wu2008missing} demonstrated that AR-based imputation methods have potential, describing a novel method using AR with a weighted voting method to impute missing nominal/categorical data but the study does not cover ordinal data. Rules are weighted and ranked according to antecedent length (specificity) as well as \textit{Confidence} and \textit{Support}. AR is well-researched as a prediction/classification method. Many other authors describe novel ranking methods as well as the use of alternative interestingness measures to improve classification accuracy , for example Laplace's Accuracy and an adjusted Chi square measure can be found in \parencite{yin2003cpar}, \parencite{liu2001classification} and \parencite{li2001cmar}. Aggregate predictions from a set of rules is also recommened to address the problem of simply using the rule with the highest \textit{Confidence} while ignoring other rules that may have only slightly lower scores. \parencite{mutter2004classification} proposes majority vote with weighting and showed significant improvements to older methods. \parencite{liu2001classification} recognizes that a consequence of generating rules with a minimum textit{Support} means it is possible that there will not be a rule to cover all instance so includes a default class (usually the majority class) as the final rule. However, \parencite{li2006predicting} states that the default assigned value may not be related to the instance data introducing noise. Other authors prefer adaptations of MVN based MI for ordinal data scenarios. For example, \parencite{plumpton2016multiple} investigated a pre-processing method for MI of Likert scales which included pre-calculated scale totals in the imputation model instead of the individual scale items to reduce the computational overhead. For the current research, this idea is can be adapted as a feature engineering technique to be used alongside the individual scale items as the aggregates provide additional information about inter-item correlations, essential to Likert scale reliability.

\section{I-ISARP}

I-ISARP is presented as a two part algorithm. An inner I-AR (Imputation by Association Rules) provides a simple mechanism for generating new values for missing data based on matching rule antecedents with data values in the observed data. An outer iterative-sequential algorithm cycles through each variable, building a propensity model by which to split the data set into several portions and building an AR-based imputation model for each one.\par
I-ISARP allows for a number of user-configurable options. The rule ranking function can be any interestingness measure. The top $n$ rules is also a user parameter along with the choice of rule aggregation method. A setting of $n = 1$ is simply the best rule selection. Minimum \textit{Support} and \textit{Confidence} for the frequent pattern discovery stage can also be controlled. The choice of whether and how to complete any unimputed values with a default class is available and early stopping can be set by maximum iterations and target convergence. The number of propensity tiers and methods to deal with class imbalance in the propensity model can also be controlled. The CARs generation step is run separately from the imputation step to provide the option to extend the dataset with engineered features such as scale totals or scale means, as suggested by \parencite{plumpton2016multiple} and \parencite{tan2005chapter7}. Currently, the optimum settings are found by experimentation but future work will focus on determining the ideal setup based on features of the target dataset.\newline

Let $\textit{lhs}(r)$ be the antecedent, or left-hand side of rule $r$ and $\textit{rhs}(r)$ be the consequent, or right-hand side. Let $J$ be the set of variables, such that for each $j$ there is some missing data, $m_{+j} > 0,\ j \in \{1,\ 2,\ \dots,\ p\  \}$. Let $R_J$ be the set of all CARs found for the set of variables J, $R_j$ be the set of CARs for variable $j$. For any single CAR $r_j$, the cardinality $|\textit{rhs}(r_j)| = 1$ and the value $k \in \{\ 1, 2,\ \dots\ ,\ K\ \}$ where $K$ is the number of levels. $X_{i}\ \textit{satisfies}\ r_j$ when all key-value pairs in $\textit{lhs}(r_j)$ have a match in the key-value pair representation of $X_{i}$. Let $\textit{agg}()$ be the aggregate voting function set by user (e.g. rounded mean, majority vote) with $N$ as the early stopping parameter. Let $\textit{srt}()$ be the precedence sorting function set by user (e.g. by \textit{Confidence}, Chi squared, etc). Assuming AR-based imputation does not always estimate a value for every missing data point, let $M'$ be the missing indicator matrix after AR-based imputation. Let $\textit{def}()$ be the default class function set by user (e.g. majority class, posterior frequency distribution). The short-hand \textit{makeCARs()} is used for the rule discovery step, which might include additional, engineered features in I-ISARP.

\begin{algorithm}
\caption{I-AR: Imputation by Association Rules}\label{ARI1}
\begin{algorithmic}[1]
\Procedure{I-AR}{$X$, $R$, $J$, $N$, $\textit{agg}()$, $\textit{def}()$, $\textit{srt}()$}
  \ForAll{$j \in J$}
    \State $C \gets [\ ]$
    \For{$r_j \in \textit{srt}(R_j)$}
      \For{$i \in B'(j)$}
        \While{$length(C) \leq N$}
          \If{$X_i\ \textit{satisfies}\ \textit{lhs}(r_j)$}
            \State $C \gets append[\ C,\ \textit{rhs}(r_j)\ ]$
          \EndIf
        \EndWhile
        \State $X_{ij} \gets \textit{agg}(C)$
      \EndFor
    \EndFor
    \If{$m'_{+j} > 0,\ m'_{ij} \in M'$}
      \State $x_{ij} \gets \textit{def}(j), \forall{i \in m'_{ij} = 1}$
    \EndIf
  \EndFor
  \State $\textbf{return }{X}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{I-ISARP: Imputation by Iterative Sequential Association Rules with Propensity}\label{ARI3}
\begin{algorithmic}[3]
\Procedure{I-ISARP}{$X$, $J$, $N$, $S$, $\textit{agg}()$, $\textit{def}()$, $\textit{srt}()$, $\textit{itermax}$, $\textit{targc}$}
\State $X' \gets X$
\State $\textbf{sort}\ J\ \textbf{by}\ M_{+j}\  \textbf{ascending}$
\For{$j \in J$}
  \State $j* \gets \textit{bootstrap } X_j$
  \For{$i \in M_{ij} = 1$}
    \State $X'_{ij} \gets \textit{random value drawn from}\ j*$ 
  \EndFor
\EndFor
\State $\textit{iter} \gets 0$
\State $c \gets \textit{targc} + 1$
\While{$\textit{iter} < \textit{itermax}\ \land \ c > \textit{targc}$}
  \State $\textit{iter} \gets \textit{iter} + 1$
  \For{$j \in J$}
    \State $ \textit{glm.fit} \gets \textit{logistic regression model of } M_j \textit{ on } X'_k,\ k \in \{ 1,\ 2,\ \dots,\ p\ \} \land j \notin k$
    \State $P \gets \textit{probability prediction of glm.fit}$
    \State $\textit{Order } X'_j \textit{ by } P$
    \State $\textit{Horizontally split } X'_j \textit{ into } S \textit{ equal sized subsets } {X'_j}_s$
    \For{$s \gets 1\ \textbf{to}\ S$}
      \State ${X'_j}_s \gets {X_j}_s$
      \State ${R_j}_s \gets \textit{makeCARs}({X'_j}_s)$
      \State $X''_s \gets \textit{run I-AR algorithm }(\ X = {X'_j}_s,\ R = {R_j}_s,\ J = j,\ \textit{agg}(),\ \textit{def}(),\ \textit{srt}()\ )$
    \EndFor
    \State $\textit{Rowbind each subset } X''_s \textit{ into a single dataset } X''$
  \EndFor
  \State $c \gets \frac{1}{|J|} \sum_{j \in J}{\sum_{i \in B'(j)} \sqrt(X''_{ij} - X'_{ij})^2}$
  \State $X' \gets X''$
\EndWhile
\State $\textbf{return}\ X'$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Experimental Study}

An experiment was conducted to compare I-ISARP to a set of well-chosen benchmark methods. Synthetic data was used, using a generation method described in \parencite{wu2015comparison} which simulates realistic Likert scales. A Structural Equation Model (SEM) was used to create two MIRVs of six items with an inter-item correlation of $\approx 0.7$. The two MIRVs were configured to have a correlation of $\approx 0.3$. The settings only need be approximate when first generated because the discretization process affects correlations and they cannot be determined analytically after this operation. Two copies of the resulting datasets from this model were discretized into seven ordinal levels with pre-defined cut points that resulted in a symmetric and a severely asymmetric distribution for comparison. MCAR, MAR and MNAR patterns were introduced according to a combination of techniques found in \parencite{wu2015comparison} and \parencite{carpita2011imputation} and these sources also informed the selection of benchmarking techniques.\par
To measure the success of an imputation method, it is necessary to demonstrate that the underlying distribution has been preserved so that further analysis can be conducted free from introduced bias. This is much more important than scoring well on prediction accuracy. Therefore, following the methods suggested in the reference papers, this research measured the Mean Absolute Scale Errors (MASE) and compared the MIRV means, standard deviations and Cronbach's alpha scores. Inter-item correlations of sets of unrelated individual items were also measured to test for any "cross-talk" between imputed values of unrelated MIRVs. These statistics were compared to the population parameters of untreated data by calculating the relative bias:

\begin{equation}
  B(\hat{Z_r}) = \frac{\hat{Z_r} - \zeta_p}{\zeta_p}
\end{equation}

where $\hat{Z_r}$ is the estimated parameter after imputation and $\zeta_p$ is the population parameter, based on the initial conditions. A value of < 0.05 was deemed to be acceptable for a well-performing imputation method \parencite{leite2010performance}.\par

The methodology conducted was as follows:

\begin{enumerate}
\item A very large sample of 500000 instances was generated and the population parameters were estimated from this.
\item A dataset of 1000 samples was then generated from the same model.
\item The three missing data patterns applied to three separate copies of the datasets: MCAR, MAR and MNAR with unobserved covariates.
\item A copy of each dataset was created for the imputation techniques so each wwould be run on its own copy.
\item Listwise deletion was performed on any remaining incomplete cases for methods that did not resolved to a default class.
\item Steps 2-5 were repeated for 100 replications.
\item Statistics of interest were estimated from each imputed dataset, including relative bias to the population parameters.
\end{enumerate}

Various papers influenced the choice of experimental design factors, including \parencite{plumpton2016multiple}, \parencite{leite2010performance}, \parencite{jonsson2006benchmarking} and \parencite{jonsson2004evaluation}. The sample size of 1000 served as a mid-point of the range used in similar experiments (200-2000). Similar experiments had missing data in proportions ranging from 0.1 to 0.55 and again, 0.3 is a useful mid-point providing adequate challenge for the method under test. The reference articles were very varied on the selection of benchmark techniques and many reported the inclusion of mean imputation, regression imputation and list-wise deletion. This may be a symptom of the relative age of some of the research, or potentially flaws in the research design. For this experiment, it was not considered worthwhile to compare any novel technique to techniques regarded as flawed or outdated in the modern literature. Focus instead was on techniques considered to be state of the art (MI and MICE) or proven to be effective on Likert scales. The Person Mean (PM), the Corrected Item Mean (CIM), Two-Way imputation (TW) and Item Correlation Substitution (ICS) methods were all recommended in \parencite{carpita2011imputation} and all experiments were repeated with a new generation of the dataset one-hundred times.\par
The experimental design factors are summarized in Table 1. A particular setup of the user configuration for I-ISARP, which was determined by experimentation to perform well with the experimental data, is summarized in Table 2. All the experiments were run on a Microsoft Surface with 8 GB RAM, 1 TB SSD HD, x64 processor, Windows 10; 64 Bit. The R programming environment, \parencite{R-base} was selected because it offers pre-existing sets of relevant, open source libraries and functions plus unlimited extensibility through a functional and object oriented programming paradigm. The R version used was 3.4.0 (2017-04-21).

<<hatwell-design-matrix, results='asis'>>=
factor_name <- c("Number of ordinal categories"
                , "Sample size"
                , "Data distributions"
                , "Proportion of missing data"
                , "Missing data mechanisms"
                , "Imputation Strategy"
                , "Benchmark methods"
                , "Data source"
                , "Number of repetitions")
factor_options <- c("7"
                , "1000"
                , "Symmetric and Severely Asym."
                , "0.3"
                , "MCAR, MAR, MNAR"
                , "Novel AR-based method"
                , "PM, CIM, TW, ICS, MI, MICE"
                , "Synthetic data"
                , "100")

cp_design_matrix <- knitr::kable(data.frame(
  "Design Factor" = factor_name
  , Options = factor_options
  , check.names = FALSE)
        , caption = "Experimental Design Matrix.")

cp_design_matrix
@

<<iisarp-config, results='asis'>>=
factor_name <- c("Top n"
                , "Ranking measure"
                , "Default class"
                , "Propensity tiers"
                , "Max. iterations"
                , "Target Convergence"
                , "m (number of pooled imputations)")
factor_options <- c("1 (best rule)"
                , "Chi square"
                , "Majority Class"
                , "2"
                , "5"
                , "36"
                , "5")

cp_design_matrix <- knitr::kable(data.frame(
  "Configuration Options" = factor_name
  , "Setting" = factor_options
  , check.names = FALSE)
        , caption = "Experimental configuration of I-ISARP.")

cp_design_matrix
@

\section{Results}

Forest plots, similar to those used in \parencite{plumpton2016multiple} were used as a preliminary visual assessment. The Kruskal-Wallis test for significance was used instead of ANOVA because the statistics measured were frequently found to be not normally distributed within groups. Each dataset (MCAR, MAR and MNAR) was tested separately, grouped on the imputation methods. A p-value of < 0.05 under the Kruskal-Wallis test was taken as evidence against the null, in favour of a difference between the groups. Tukey's HSD was used for post-hoc confirmation of differences between specific methods. An adjusted p-value of < 0.05 under Tukey's HSD was taken as evidence against the null hypothesis, in favour of the relative performance seen in the plots.

<<bm_wu_sym_load_data>>=
load("bm1_wu_sym_results.RData")

res <- bm_wu_sym_results

res$bottom_2 <- NULL

res_items <- names(res)

for(ri in res_items) {
  res[[ri]]$dataset <- sub("wu_sym_", "", res[[ri]]$dataset)
  res[[ri]]$dataset <- sub("_0.3_1000", "", res[[ri]]$dataset)
  res[[ri]]$variant <- sub("ibestdc1chip", "I-ISARP", res[[ri]]$variant)
  res[[ri]]$variant <- sub("amelia", "MI", res[[ri]]$variant)
  res[[ri]]$variant <- sub("mice", "MICE", res[[ri]]$variant)
}

dtsts <- unique(res$results$dataset)

pop <- wu_stats_pop_sym
pop.frame <- data.frame(stats = names(pop), value = unlist(pop))
@

<<bm-wu-sym-plots-mase, fig.height=2.25, fig.cap='Mean Absolute Scale Errors after imputation with 95pc confidence interval on 99 df.'>>=
stats_names <- c("mase_A", "mase_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
                  , shape = dataset
            )
) +
  labs(y = "method") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
@

<<bm-wu-sym-plots-mean, fig.height=2.25, fig.cap='Scale means after imputation with 95pc confidence interval on 99 df. Dotted line shows population parameter.'>>=
stats_names <- c("mean_A", "mean_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(y = factor(variant)
                  , x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , colour = dataset
                  , shape = dataset
            )
) +
  labs(y = "method") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
@

<<bm-wu-sym-plots-sd, fig.height=2.25, fig.cap='Scale standard deviations after imputation with 95pc confidence interval on 99 df. Dotted line shows population parameter.'>>=
stats_names <- c("sd_A", "sd_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
                  , shape = dataset
            )
) +
  labs(y = "method") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
            , stats %in% stats_names)
            , aes(xintercept = value)
            , colour = myPalDark[3]
            , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
@

<<bm-wu-sym-plots-alpha, fig.height=2.25, fig.cap='Cronbach\'s alpha after imputation with 95pc confidence interval on 99 df. Dotted line shows population parameter.'>>=
stats_names <- c("alpha_A", "alpha_B")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
                  , shape = dataset
            )
) +
  labs(y = "method") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
@

<<bm-wu-sym-plots-splith, fig.height=2.25, fig.cap='Split-half correlation after imputation with 95pc confidence interval on 99 df. Dotted line shows population parameter.'>>=
stats_names <- c("splith_mix")
g <- ggplot(data = subset(res$ci_data
                          , stats %in% stats_names)
            , aes(x = mean
                  , xmin = ci_lwr
                  , xmax = ci_upr
                  , y = variant
                  , colour = dataset
                  , shape = dataset
            )
) +
  labs(y = "method") +
  facet_wrap(~stats, scales = "free") +
  geom_point(size = 2) +
  geom_errorbarh(size = 0.5, height = 0.25, alpha = 0.5) +
  geom_vline(data = subset(pop.frame
                           , stats %in% stats_names)
             , aes(xintercept = value)
             , colour = myPalDark[3]
             , linetype = "dotted") +
  myGgTheme +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  myGgColourScale
g
@

<<bm-wu-sym-sd-A-relb>>=
tab <- subset(res$qdata
              , res$qdata$stats == "sd_A"
              , c("dataset", "variant", "mean", "rel_bias"))
tab <- head(tab, 14)
names(tab) <- c("dataset", "method", "mean", "rel_bias")
relb_sdA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Scale A standard deviation for each imputation method (excerpt).")

relb_sdA
@

<<bm-wu-sym-alpha-A-relb>>=
tab <- subset(res$qdata
              , res$qdata$stats == "alpha_A"
              , c("dataset", "variant", "mean", "rel_bias"))
tab <- head(tab, 14)
names(tab) <- c("dataset", "method", "mean", "rel_bias")
relb_alphaA <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of Cronbach's alpha of Scale A for each imputation method (excerpt).")

relb_alphaA
@

<<bm-wu-sym-splith-relb>>=
tab <- subset(res$qdata
              , res$qdata$stats == "splith_mix"
              , c("dataset", "variant", "mean", "rel_bias"))
tab <- head(tab, 14)
names(tab) <- c("dataset", "method", "mean", "rel_bias")
relb_splith <- knitr::kable(
  tab[order(tab$dataset, -abs(tab$rel_bias), method = "radix", decreasing = c(FALSE, TRUE)), ]
  , digits = 5
  , row.names = FALSE
  , caption = "Relative bias of split-half correlation for each imputation method (excerpt).")

relb_splith
@

I-ISARP significantly outperformed the MI and MICE methods on both scales MASE. However, the single imputation methods perform somewhat better on this measure, with no clear leader among them. There was no difference between any of the methods when comparing scale means except that the PM did slightly worse on MAR data but this finding does not impact the current research. When measuring the bias in the standard deviation, I-ISARP performed less well than the benchmarks but was still within an acceptable relative bias of < 0.05 except in the MAR case on Scale A where the relative bias is borderline. Cronbach's alpha, which is a crucial statistic in Likert scale analysis was almost uniformly biased upwards by around two percentage points by all the single imputation methods, while I-ISARP and MI tended towards a downward bias of a smaller magnitude. I-ISARP beat MI in the MCAR and MNAR cases. The introduced biases were enough to affect the decision to accept or reject a reliability analysis based on a borderline case of alpha $\approx 0.7$ but upwards bias may be more serious, resulting in a higher false positive rate. Overall MICE was the best performer for this measure, returning an estimate with no detectable difference from the population parameter. Split-half correlation returned a dramatic result, in that the upwards bias from the single imputation techniques was so great that the two scales would appear to be associated in a reliability test. This has very serious consequences for subsequent data analysis. Contrastingly, I-ISARP compares very favourably with MICE and MI for this statistic. All three MI techniques very closely preserve the population parameter and avoid "cross-talk" between the scales after imputation.

\section{Discussion}

I-ISARP had a lower MASE on both scales than benchmark MI methods and although it was beaten by the single imputation methods on this measure, results on other measures serve to discredit those methods for the use case under test. A smaller MASE would be prioritized in any analysis of Likert scales, so this is a key factor in determining a well-performing imputation method. A competing statistic is the scale means and here there was no detectable difference between any method. It is an open research question as to whether scale means or sums should be preferred in a dataset that has undergone imputation, based on the level of introduced bias at the individual item level.\par
MI and MICE were better at preserving the standard deviations than this specific configuration of I-ISARP, possibly because the it used a majority class default for any values remaining unimputed where no matching rules were found.\par
On the Cronbach's alpha statistic I-ISARP compared well, beating MI in some cases. It also compared very well to both MI and MICE for maintaining split-half correlation between unrelated items. The single imputation methods performed disasterously here and would be sure to increase the risk of fallacious conclusions in any subsequent analysis.\par
Figures 6-8 are diagnostic plots for imputation processes over selected individual items. They superimpose the density of the untreated data with the density of the imputed values. The distribution of values imputed by the I-ISARP method appear more closely to resemble the underlying distribution, while the values imputed by MICE appear to be strongly influenced by the MVN assumption associated with that method.

<<diag-plots-setup>>=
m <- 5
varnames <-  paste0(rep(c("A", "B"), each = 3), 1:3)
allvarnames <- paste0(rep(c("A", "B"), each = 6), 1:6)
methods <- c("MI", "MICE", "I.ISARP")

myFills <- c(I.ISARP = myPal[6], MICE = myPal[8])
myCols <- c(untreated = myPal[7])
myLineTypes <- c(I.ISARP = 5, MICE = 3)

# sample2 is best dc1 prop 2
# sample3 is best dc2 prop 4
# sample4 for is top 2 mean dc2 prop 4
# sample5 for is rhsfreq mean dc1 prop 4 - A2 and B1 is interesting
@


<<dens-diag1, fig.height=2.5, fig.cap="Imputation diagnostic plot. In this case, four propensity levels were used along with a stochastic default class using the posterior frequency distribution.">>=
load("sample_results3.RData")
vv <- "A1"

res <- sample_results$wu_sasym_MCAR_0.3_1000
names(res) <- c("PM"
                , "CIM"
                , "TW"
                , "ICS"
                , "I.ISARP"
                , "MI"
                , "MICE"
                , "untreated"
                , "to_impute")

completed_results <- list()
for (meth in methods) {
  completed_results[[meth]] <- list()
  for (v in varnames) {
    pooled <- matrix(NA, nrow = 1000, ncol = m)
    for (n in 1:m) {
      pooled[, n] <- res[[meth]][[n]][[v]]
    }
    completed_results[[meth]][[v]] <- round(rowMeans(pooled))
  }
  completed_results[[meth]] <- cbind(completed_results[[meth]]
                                     , sample_results$wu_sasym_MCAR_0.3_1000$untreated[, c(4:6, 10:12)])
  completed_results[[meth]] <- completed_results[[meth]][, allvarnames]
}

all_results <- append(completed_results
                      , list(PM = sample_results$wu_sasym_MCAR_0.3_1000$PM
                             , CIM = sample_results$wu_sasym_MCAR_0.3_1000$CIM
                             , TW = sample_results$wu_sasym_MCAR_0.3_1000$TW
                             , ICS = sample_results$wu_sasym_MCAR_0.3_1000$ICS
                             , untreated = sample_results$wu_sasym_MCAR_0.3_1000$untreated))

results_byvar <- list()
for (v in varnames) {
  for (dt in names(res)) {
    results_byvar[[v]][[dt]] <- all_results[[dt]][[v]]
  }
  results_byvar[[v]] <- as.data.frame(results_byvar[[v]])
}

g <- ggplot(data = results_byvar[[vv]][res$to_impute$mim$B_j[[vv]], ]
            , aes(x = untreated
                  , colour = "untreated"))
g <- g + geom_density(data = results_byvar[[vv]][res$to_impute$mim$B_comp_j[[vv]], ]
                      , aes(x = I.ISARP
                            , fill = "I.ISARP"
                            , linetype = "I.ISARP")
                      , alpha = 0.5
                      , colour = "grey60"
                      , size = 1)
g <- g + geom_density(data = results_byvar[[vv]][res$to_impute$mim$B_comp_j[[vv]], ]
                      , aes(x = MICE
                            , fill = "MICE"
                            , linetype = "MICE")
                      , alpha = 0.5
                      , colour = "grey36"
                      , size = 1)
g <- g + geom_density() # data = sample_results$wu_sasym_MCAR_0.3_1000$untreated
g + myGgTheme + theme_bw() + xlim(0, 8) +
  scale_colour_manual(name = ""
                      , values = myCols
                      , guide = "legend") +
  scale_fill_manual(name = "imputation \nmethod"
                    , values = myFills
                    , guide = "legend") +
  
  scale_linetype_manual(name = ""
                        , values = myLineTypes
                        , guide = "legend") +
  labs(x = "Data Value")
@

<<dens-diag2, fig.height=2.5, fig.cap="Imputation diagnostic plot. In this case, four propensity levels were used along with a stochastic default class using the posterior frequency distribution. Even on symmetric data, this configuration more closely follows the underlying distribution than MICE, which over-emphasises the central tendency.">>=
vv <- "B3"

g <- ggplot(data = results_byvar[[vv]][res$to_impute$mim$B_j[[vv]], ]
            , aes(x = untreated
                  , colour = "untreated"))
g <- g + geom_density(data = results_byvar[[vv]][res$to_impute$mim$B_comp_j[[vv]], ]
                      , aes(x = I.ISARP
                            , fill = "I.ISARP"
                            , linetype = "I.ISARP")
                      , alpha = 0.5
                      , colour = "grey60"
                      , size = 1)
g <- g + geom_density(data = results_byvar[[vv]][res$to_impute$mim$B_comp_j[[vv]], ]
                      , aes(x = MICE
                            , fill = "MICE"
                            , linetype = "MICE")
                      , alpha = 0.5
                      , colour = "grey36"
                      , size = 1)
g <- g + geom_density() # data = sample_results$wu_sasym_MCAR_0.3_1000$untreated
g + myGgTheme + theme_bw() + xlim(0, 8) +
  scale_colour_manual(name = ""
                      , values = myCols
                      , guide = "legend") +
  scale_fill_manual(name = "imputation \nmethod"
                    , values = myFills
                    , guide = "legend") +
  
  scale_linetype_manual(name = ""
                        , values = myLineTypes
                        , guide = "legend") +
  labs(x = "Data Value")
@

<<dens-diag3, fig.height=2.5, fig.cap="Imputation diagnostic plot. In this case, four propensity levels were used along with a stochastic imputation method based on the frequency of consequent values of all the matching rules for each data point. Default class was set to the majority class where no matching rules were found.">>=
load("sample_results5.RData")
vv <- "B1"

res <- sample_results$wu_sasym_MCAR_0.3_1000
names(res) <- c("PM"
                , "CIM"
                , "TW"
                , "ICS"
                , "I.ISARP"
                , "MI"
                , "MICE"
                , "untreated"
                , "to_impute")

completed_results <- list()
for (meth in methods) {
  completed_results[[meth]] <- list()
  for (v in varnames) {
    pooled <- matrix(NA, nrow = 1000, ncol = m)
    for (n in 1:m) {
      pooled[, n] <- res[[meth]][[n]][[v]]
    }
    completed_results[[meth]][[v]] <- round(rowMeans(pooled))
  }
  completed_results[[meth]] <- cbind(completed_results[[meth]]
                                     , sample_results$wu_sasym_MCAR_0.3_1000$untreated[, c(4:6, 10:12)])
  completed_results[[meth]] <- completed_results[[meth]][, allvarnames]
}

all_results <- append(completed_results
                      , list(PM = sample_results$wu_sasym_MCAR_0.3_1000$PM
                             , CIM = sample_results$wu_sasym_MCAR_0.3_1000$CIM
                             , TW = sample_results$wu_sasym_MCAR_0.3_1000$TW
                             , ICS = sample_results$wu_sasym_MCAR_0.3_1000$ICS
                             , untreated = sample_results$wu_sasym_MCAR_0.3_1000$untreated))

results_byvar <- list()
for (v in varnames) {
  for (dt in names(res)) {
    results_byvar[[v]][[dt]] <- all_results[[dt]][[v]]
  }
  results_byvar[[v]] <- as.data.frame(results_byvar[[v]])
}

g <- ggplot(data = results_byvar[[vv]][res$to_impute$mim$B_j[[vv]], ]
            , aes(x = untreated
                  , colour = "untreated"))
g <- g + geom_density(data = results_byvar[[vv]][res$to_impute$mim$B_comp_j[[vv]], ]
                      , aes(x = I.ISARP
                            , fill = "I.ISARP"
                            , linetype = "I.ISARP")
                      , alpha = 0.5
                      , colour = "grey60"
                      , size = 1)
g <- g + geom_density(data = results_byvar[[vv]][res$to_impute$mim$B_comp_j[[vv]], ]
                      , aes(x = MICE
                            , fill = "MICE"
                            , linetype = "MICE")
                      , alpha = 0.5
                      , colour = "grey36"
                      , size = 1)
g <- g + geom_density() # data = sample_results$wu_sasym_MCAR_0.3_1000$untreated
g + myGgTheme + theme_bw() + xlim(0, 8) +
  scale_colour_manual(name = ""
                      , values = myCols
                      , guide = "legend") +
  scale_fill_manual(name = "imputation \nmethod"
                    , values = myFills
                    , guide = "legend") +
  
  scale_linetype_manual(name = ""
                        , values = myLineTypes
                        , guide = "legend") +
  labs(x = "Data Value")
@


\section{Conclusions}

Overall, I-ISARP has compared favourably with state of the art methods and, given the distribution-free nature of the imputed values, it is reasonable to expect that with further research and refinement I-ISARP could produce better results in situations where traditional MI is challenged, such as highly skewed or multi-modal ordinal data. Suggestions for future work include further experimentation with stochastic default class methods to ensure I-ISARP better preserves the scale standard deviations, and implementing the multi-class based \textit{Support} levels, suggested by \parencite{liu2001classification} to further improve the performance in highly skewed data.\par
As mentioned previously, I-ISARP offers many tuning parameters and well-performing configurations were found by experimentation. An important avenue for further research is to determine analytical methods or simple rules of thumb to support the best tuning options from statistical properties of the target dataset. As well as exploratory methods and an initial reliability analysis, cumulative odds models and penalized regression are both recommended for use with ordinal data and could be investigated further in this context.\par
For this research, I-ISARP has been implemented as an R package with the \textit{apriori} algorithm from the \textit{arules} package \parencite{R-arules} at its core. However, this would ideally be substituted in the future with the FP-growth algorithm which is widely reported to have much faster performance e.g. \parencite{li2001cmar}.\par
A suprising discovery of this research, unrelated to the main topic, was that MNAR data provided to be no special challenge to any imputation method used. This runs counter to all the discussions found in the literature and is potentially a significant new area of research in its own right. Another discovery was the inability of several of the benchmark methods maintain separation of non-related MIRVs. This surpring result may be of interest to the statistical community suggesting that more work should be done regarding the use of these methods for anything other than imputation within a single MIRV.

\printbibliography

\end{document}